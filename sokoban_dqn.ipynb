{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67c42a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install opencv-python # to use the cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "27ac15da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gym\n",
    "import gym_sokoban\n",
    "import matplotlib.pyplot as plt\n",
    "from custom_sokoban_env import my_sokoban_env\n",
    "import sokoban_tabular\n",
    "import time\n",
    "import sys\n",
    "import random \n",
    "import itertools\n",
    "import cv2\n",
    "from dqn import train_dqn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "982b3842",
   "metadata": {},
   "source": [
    "# Check System Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd7ffbe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install gym==0.21.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "69edbc81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.21.0\n"
     ]
    }
   ],
   "source": [
    "print(gym.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "01b9ecb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.9.17 (main, Jul  5 2023, 21:22:06) [MSC v.1916 64 bit (AMD64)]\n"
     ]
    }
   ],
   "source": [
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a216e596",
   "metadata": {},
   "source": [
    "# Define the environment and number of boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "34a5f86c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create the Sokoban environment from sokoban versions.\n",
    "# env_name = 'Sokoban-v2'\n",
    "# game_env = gym.make(env_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "557e9ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Sokoban environment custom\n",
    "# game_env = my_sokoban_env(dim_room=(10, 10), num_boxes=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "59d60106",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to convert state to a tuple\n",
    "def state_to_tuple(state):\n",
    "    return tuple(state.reshape(-1))\n",
    "\n",
    "# Save the original state of the environment\n",
    "# initial_state = game_env.reset()\n",
    "# initial_state_tuple = state_to_tuple(initial_state)\n",
    "# game_env.render(mode='human')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "99e7b824",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Action lookup\n",
    "# ACTION_LOOKUP = env.unwrapped.get_action_lookup()\n",
    "# Convert state to tuple representation (for tabular SARSA)\n",
    "def state_to_tuple(state):\n",
    "    return tuple(state.ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87aae971",
   "metadata": {},
   "source": [
    "# Save One Initial State for Consistancy"
   ]
  },
  {
   "attachments": {
    "three_box_env.JPG": {
     "image/jpeg": "/9j/4AAQSkZJRgABAQEAkACQAAD/4RCoRXhpZgAATU0AKgAAAAgABAE7AAIAAAASAAAISodpAAQAAAABAAAIXJydAAEAAAAkAAAQfOocAAcAAAgMAAAAPgAAAAAc6gAAAAgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAEFtaXJhbGkgTGFsZWhwb3VyAAAB6hwABwAACAwAAAhuAAAAABzqAAAACAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABBAG0AaQByAGEAbABpACAATABhAGwAZQBoAHAAbwB1AHIAAAD/4QpqaHR0cDovL25zLmFkb2JlLmNvbS94YXAvMS4wLwA8P3hwYWNrZXQgYmVnaW49J++7vycgaWQ9J1c1TTBNcENlaGlIenJlU3pOVGN6a2M5ZCc/Pg0KPHg6eG1wbWV0YSB4bWxuczp4PSJhZG9iZTpuczptZXRhLyI+PHJkZjpSREYgeG1sbnM6cmRmPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5LzAyLzIyLXJkZi1zeW50YXgtbnMjIj48cmRmOkRlc2NyaXB0aW9uIHJkZjphYm91dD0idXVpZDpmYWY1YmRkNS1iYTNkLTExZGEtYWQzMS1kMzNkNzUxODJmMWIiIHhtbG5zOmRjPSJodHRwOi8vcHVybC5vcmcvZGMvZWxlbWVudHMvMS4xLyIvPjxyZGY6RGVzY3JpcHRpb24gcmRmOmFib3V0PSJ1dWlkOmZhZjViZGQ1LWJhM2QtMTFkYS1hZDMxLWQzM2Q3NTE4MmYxYiIgeG1sbnM6ZGM9Imh0dHA6Ly9wdXJsLm9yZy9kYy9lbGVtZW50cy8xLjEvIj48ZGM6Y3JlYXRvcj48cmRmOlNlcSB4bWxuczpyZGY9Imh0dHA6Ly93d3cudzMub3JnLzE5OTkvMDIvMjItcmRmLXN5bnRheC1ucyMiPjxyZGY6bGk+QW1pcmFsaSBMYWxlaHBvdXI8L3JkZjpsaT48L3JkZjpTZXE+DQoJCQk8L2RjOmNyZWF0b3I+PC9yZGY6RGVzY3JpcHRpb24+PC9yZGY6UkRGPjwveDp4bXBtZXRhPg0KICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgIAogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgCiAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgIAogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgCiAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgIAogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgCiAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgIAogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgCiAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgIAogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgCiAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgIAogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgCiAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgIAogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgCiAgICAgICAgICAgICAgICAgICAgICAgICAgICA8P3hwYWNrZXQgZW5kPSd3Jz8+/9sAQwAHBQUGBQQHBgUGCAcHCAoRCwoJCQoVDxAMERgVGhkYFRgXGx4nIRsdJR0XGCIuIiUoKSssKxogLzMvKjInKisq/9sAQwEHCAgKCQoUCwsUKhwYHCoqKioqKioqKioqKioqKioqKioqKioqKioqKioqKioqKioqKioqKioqKioqKioqKioq/8AAEQgA8wD3AwEiAAIRAQMRAf/EAB8AAAEFAQEBAQEBAAAAAAAAAAABAgMEBQYHCAkKC//EALUQAAIBAwMCBAMFBQQEAAABfQECAwAEEQUSITFBBhNRYQcicRQygZGhCCNCscEVUtHwJDNicoIJChYXGBkaJSYnKCkqNDU2Nzg5OkNERUZHSElKU1RVVldYWVpjZGVmZ2hpanN0dXZ3eHl6g4SFhoeIiYqSk5SVlpeYmZqio6Slpqeoqaqys7S1tre4ubrCw8TFxsfIycrS09TV1tfY2drh4uPk5ebn6Onq8fLz9PX29/j5+v/EAB8BAAMBAQEBAQEBAQEAAAAAAAABAgMEBQYHCAkKC//EALURAAIBAgQEAwQHBQQEAAECdwABAgMRBAUhMQYSQVEHYXETIjKBCBRCkaGxwQkjM1LwFWJy0QoWJDThJfEXGBkaJicoKSo1Njc4OTpDREVGR0hJSlNUVVZXWFlaY2RlZmdoaWpzdHV2d3h5eoKDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uLj5OXm5+jp6vLz9PX29/j5+v/aAAwDAQACEQMRAD8A3/Hev6l4c+IUF7o0wiuG0p4yxjD/ACmZCeCD6Cqdr8UPF8lldySX6740Up/o0fBJx/dp/wASb+TTvHVvNEqsx0xlw4yP9cv+FYV34jubeK2ZIYf30Qdsr3ya8bF1OWq/fa02PfwNJToL92nd7vy+RrWPxS8YzX8Ect+pRnAb/RYxxn/dpk/xU8ZJcSKt+u1XIH+ix9M/7tZlh4jubmWRXhhGyJnGF7gVV/4Su7/54Qf981xOt7i/ev8AH/M9BUE5v9zH8P8AI6S1+KHi+Syu5JL9d8aKU/0aPgk4/u1HY/FLxjNfwRy36lGcBv8ARYxxn/drJu/EdzbxWzJDD++iDtle+TRYeI7m5lkV4YRsiZxhe4FX7V8yj7V/j/mR7Fckpexjr6adOxpz/FTxklxIq367Vcgf6LH0z/u1Pa/FDxfJZXckl+u+NFKf6NHwScf3a5v/AISu7/54Qf8AfNWrvxHc28VsyQw/vog7ZXvk1Ma28vav8f8AMqWH0UfYxv8ALp8jWsfil4xmv4I5b9SjOA3+ixjjP+7TJ/ip4yS4kVb9dquQP9Fj6Z/3azLDxHc3MsivDCNkTOML3Aqr/wAJXd/88IP++aTre4v3r/H/ADGqCc3+5j+H+R0lr8UPF8lldySX6740Up/o0fBJx/dqOx+KXjGa/gjlv1KM4Df6LGOM/wC7WTd+I7m3itmSGH99EHbK98miw8R3NzLIrwwjZEzjC9wKv2r5lH2r/H/Mj2K5JS9jHX006djTn+KnjJLiRVv12q5A/wBFj6Z/3antfih4vksruSS/XfGilP8ARo+CTj+7XN/8JXd/88IP++atXfiO5t4rZkhh/fRB2yvfJqY1t5e1f4/5lSw+ij7GN/l0+RrWPxS8YzX8Ect+pRnAb/RYxxn/AHaZP8VPGSXEirfrtVyB/osfTP8Au1mWHiO5uZZFeGEbImcYXuBVX/hK7v8A54Qf980nW9xfvX+P+Y1QTm/3Mfw/yOktfih4vksruSS/XfGilP8ARo+CTj+7Udj8UvGM1/BHLfqUZwG/0WMcZ/3aybvxHc28VsyQw/vog7ZXvk0WHiO5uZZFeGEbImcYXuBV+1fMo+1f4/5kexXJKXsY6+mnTsac/wAVPGSXEirfrtVyB/osfTP+7U9r8UPF8lldySX6740Up/o0fBJx/drm/wDhK7v/AJ4Qf981au/EdzbxWzJDD++iDtle+TUxrby9q/x/zKlh9FH2Mb/Lp8jWsfil4xmv4I5b9SjOA3+ixjjP+7TJ/ip4yS4kVb9dquQP9Fj6Z/3azLDxHc3MsivDCNkTOML3Aqr/AMJXd/8APCD/AL5pOt7i/ev8f8xqgnN/uY/h/kdJa/FDxfJZXckl+u+NFKf6NHwScf3ajsfil4xmv4I5b9SjOA3+ixjjP+7WTd+I7m3itmSGH99EHbK98miw8R3NzLIrwwjZEzjC9wKv2r5lH2r/AB/zI9iuSUvYx19NOnY05/ip4yS4kVb9dquQP9Fj6Z/3antfih4vksruSS/XfGilP9Gj4JOP7tc3/wAJXd/88IP++atXfiO5t4rZkhh/fRB2yvfJqY1t5e1f4/5lSw+ij7GN/l0+RrWPxS8YzX8Ect+pRnAb/RYxxn/dpk/xU8ZJcSKt+u1XIH+ix9M/7tZlh4jubmWRXhhGyJnGF7gVV/4Su7/54Qf980nW9xfvX+P+Y1QTm/3Mfw/yOktfih4vksruSS/XfGilP9Gj4JOP7tR2PxS8YzX8Ect+pRnAb/RYxxn/AHaybvxHc28VsyQw/vog7ZXvk0WHiO5uZZFeGEbImcYXuBV+1fMo+1f4/wCZHsVySl7GOvpp07Fbxp421/XbGO21bUAsEF8HjYQom07JB1A9CR+NFZ2ua5eahYwIttDI6XSsqBfvfu5B/I0V6+DlzUr81/U8LHw5K/LyqOi0R3HxIu4rPx3byT263C/2Y42N6+cvNYcWs2lzazSPpsWLdBgHB4JxjpV/4qLL/wAJjbiQq5/s5sbEI/5ar7muYsUYabqHyn/Vr2/2q87GVZxxHKtrfoergKNOWFUnvfu+6NWz1y0lu44k0yKMynYSMdD+FRy65YxzOn9kwnaxGeP8KydMRhqltlT/AK1e3vUV0j/bJvlb/WN2964PrFXkv59ken9Vpe0t5d3/AJnRRazaXNrNI+mxYt0GAcHgnGOlMs9ctJbuOJNMijMp2EjHQ/hWVYow03UPlP8Aq17f7VRaYjDVLbKn/Wr296pV6l4+fku5Dw1K0/LzfY1pdcsY5nT+yYTtYjPH+FTxazaXNrNI+mxYt0GAcHgnGOlc7dI/2yb5W/1jdverVijDTdQ+U/6te3+1SjiKjk169EVPDUlBP06vv6mrZ65aS3ccSaZFGZTsJGOh/Co5dcsY5nT+yYTtYjPH+FZOmIw1S2yp/wBavb3qK6R/tk3yt/rG7e9L6xV5L+fZD+q0vaW8u7/zOii1m0ubWaR9NixboMA4PBOMdKZZ65aS3ccSaZFGZTsJGOh/CsqxRhpuofKf9Wvb/aqLTEYapbZU/wCtXt71Sr1Lx8/JdyHhqVp+Xm+xrS65YxzOn9kwnaxGeP8ACp4tZtLm1mkfTYsW6DAODwTjHSuA8bX93plu01oxjdrgqTtzxz61x0fjPXI45I0vMLIAGGxecc+lddCliKy501bXp/wDhxNbC0JKDTvp1/4J7bZ65aS3ccSaZFGZTsJGOh/Co5dcsY5nT+yYTtYjPH+FeKxeMdbhlWSO7wynIOxeD+VNbxdrTuWa7yWOT8g/wrb6piuW11f+vIw+u4Pmvyyt6/8ABPc4tZtLm1mkfTYsW6DAODwTjHSmWeuWkt3HEmmRRmU7CRjofwrxKPxnrkcckaXmFkADDYvOOfSki8Y63DKskd3hlOQdi8H8qf1XE3Wq8/6sL67g7SXLLy1/4Pc9ql1yxjmdP7JhO1iM8f4VPFrNpc2s0j6bFi3QYBweCcY6V4Y3i7Wncs13kscn5B/hT4/GeuRxyRpeYWQAMNi8459KSwuJvq1b+vIcsbg2tIyv6/f1PbbPXLSW7jiTTIozKdhIx0P4VHLrljHM6f2TCdrEZ4/wrxWLxjrcMqyR3eGU5B2Lwfyrb8K65qOr6vKl7N5o8svgKBzkelZ1aGJp0nJtaeX/AADWjicJVrKEU9fP/gnq0Ws2lzazSPpsWLdBgHB4JxjpTLPXLSW7jiTTIozKdhIx0P4VlWKMNN1D5T/q17f7VRaYjDVLbKn/AFq9veuJV6l4+fku56Dw1K0/LzfY1pdcsY5nT+yYTtYjPH+FTxazaXNrNI+mxYt0GAcHgnGOlc7dI/2yb5W/1jdverVijDTdQ+U/6te3+1SjiKjk169EVPDUlBP06vv6mrZ65aS3ccSaZFGZTsJGOh/Co5dcsY5nT+yYTtYjPH+FZOmIw1S2yp/1q9veorpH+2TfK3+sbt70vrFXkv59kP6rS9pby7v/ADOii1m0ubWaR9NixboMA4PBOMdKZZ65aS3ccSaZFGZTsJGOh/CsqxRhpuofKf8AVr2/2qi0xGGqW2VP+tXt71Sr1Lx8/JdyHhqVp+Xm+xe1HULe5mt4ILJIGjvOXXviKUUVnyqw1JOMf6WcEj/pnJRXu4GTlRu+7PnMxhGFe0eyO2+IepzWPjiCdEjZv7NZcMOMecv+FY134jubeK2ZIYf30Qdsr3ya2/iHdRWPjqCSe3W4U6Y42N/12XmsaLWbS5tZpH02LFugwDg8E4x0rjxc2qrip20O7AwToqTp31G2HiO5uZZFeGEbImcYXuBVX/hK7v8A54Qf981Zs9ctJbuOJNMijMp2EjHQ/hUcuuWMczp/ZMJ2sRnj/CuN1Hyp+1/BnoKlHna9j+KJbvxHc28VsyQw/vog7ZXvk0WHiO5uZZFeGEbImcYXuBTotZtLm1mkfTYsW6DAODwTjHSmWeuWkt3HEmmRRmU7CRjofwqvaPmT9po/JkeyXI17LVea9St/wld3/wA8IP8AvmrV34jubeK2ZIYf30Qdsr3yail1yxjmdP7JhO1iM8f4VPFrNpc2s0j6bFi3QYBweCcY6VMaktV7XX0ZUqUdJex09UNsPEdzcyyK8MI2RM4wvcCqv/CV3f8Azwg/75qzZ65aS3ccSaZFGZTsJGOh/Co5dcsY5nT+yYTtYjPH+FDqPlT9r+DGqUedr2P4olu/EdzbxWzJDD++iDtle+TRYeI7m5lkV4YRsiZxhe4FOi1m0ubWaR9NixboMA4PBOMdKZZ65aS3ccSaZFGZTsJGOh/Cq9o+ZP2mj8mR7JcjXstV5r1OG+JWtz6l4ehimjjUC4DZQc9DXl1eqfFDULa40NIILKOBkufvr3wCK8rr18G26WsrnhZgkq+keXRaBRRRXYcAUUUUAFFFFABXYfDXUJNO8QzSxIjE25XDjI6iuPrsfhpeRWXiKaSe3W4U25G1u3I5rnxLtRk72OnCK9eKtfXY9au/EdzbxWzJDD++iDtle+TRYeI7m5lkV4YRsiZxhe4FOi1m0ubWaR9NixboMA4PBOMdKZZ65aS3ccSaZFGZTsJGOh/CvE9o+ZP2mj8mfR+yXI17LVea9St/wld3/wA8IP8AvmrV34jubeK2ZIYf30Qdsr3yail1yxjmdP7JhO1iM8f4VPFrNpc2s0j6bFi3QYBweCcY6VMaktV7XX0ZUqUdJex09UNsPEdzcyyK8MI2RM4wvcCqv/CV3f8Azwg/75qzZ65aS3ccSaZFGZTsJGOh/Co5dcsY5nT+yYTtYjPH+FDqPlT9r+DGqUedr2P4olu/EdzbxWzJDD++iDtle+TRYeI7m5lkV4YRsiZxhe4FOi1m0ubWaR9NixboMA4PBOMdKZZ65aS3ccSaZFGZTsJGOh/Cq9o+ZP2mj8mR7JcjXstV5r1M691ufURaxyxxKFugwKj/AKZSD+tFP1O/t7mS3ggskgaO85de+I5RRXr4Nt0tZXPCx6Sr6R5dFodF8V1J8ZW4UE/8S5un/XVa5axRhpuofKf9Wvb/AGq7P4kX8mneOreaJVZjpjLhxkf65f8ACsK78R3NvFbMkMP76IO2V75NedjY0/buUpW07fI9bL5Vfq6jGN9e/bUxNMRhqltlT/rV7e9RXSP9sm+Vv9Y3b3roLDxHc3MsivDCNkTOML3Aqr/wld3/AM8IP++a89wo8iXN+B6aqV3Ub5Ft3/4BTsUYabqHyn/Vr2/2qi0xGGqW2VP+tXt71t3fiO5t4rZkhh/fRB2yvfJosPEdzcyyK8MI2RM4wvcCr5KXNGPNt5fMj2lbklLk0fn8uxwXja/u9Mt2mtGMbtcFSdueOfWuOj8Z65HHJGl5hZAAw2Lzjn0rtPiVrc+peHoYpo41AuA2UHPQ15dXr4KjRlS5kr762PBzCvXjW5W2tFombkXjHW4ZVkju8MpyDsXg/lTW8Xa07lmu8ljk/IP8KxaK7Pq9G1uVfccH1qve/O/vZux+M9cjjkjS8wsgAYbF5xz6UkXjHW4ZVkju8MpyDsXg/lWHRT+r0v5V9wfWa/8AO/vNHUde1DVY9l9P5i7t+NoHP4VnUUVpGMYK0VYynOU3eTuwrqfAGjWeua7LbX8PnRiEsFyRzkelctXoXwX/AOR5/wC2J/mK4syqSp4OpOLs0jfCW9vHmV0egWHwp8L3O9JrVkmQ8p5jcD86tS/B/wAKxxM/2dhgZ+Z2x/Oup1a2+z/6fbnZIh+YD+Km207axKFm/dxRgEx/3z/hX5q8wxslzqrK3XU950YSXtIpcvXRaHinxD8I6ZoOhwXOn2nkvJNtDbidwwfX6V5vXunx1UL4fsQowBMMD8DXhdffZHXnXwSqTd3dni47ldW8VZWCrNjqNzpsxls5PLcrtJwDxVaivalFSVmccZSi+aLszdj8Z65HHJGl5hZAAw2Lzjn0pIvGOtwyrJHd4ZTkHYvB/KsOisvq9L+VfcbfWa/87+82m8Xa07lmu8ljk/IP8KfH4z1yOOSNLzCyABhsXnHPpWFRR9Xo/wAq+4PrVdq3O/vNyLxjrcMqyR3eGU5B2Lwfyrb8K65qOr6vKl7N5o8svgKBzkelcRXYfDXUJNO8QzSxIjE25XDjI6iufE0KKoy0S+R1YTE13iI+838z0WxRhpuofKf9Wvb/AGqi0xGGqW2VP+tXt71t3fiO5t4rZkhh/fRB2yvfJosPEdzcyyK8MI2RM4wvcCvD5KXNGPNt5fM+j9pW5JS5NH5/LsYUykakmQQPtZ7f7ElFW7zWp9T+yRzRxqFug2UGD/qpKK9zA8vsfdd1dnzeZc31j31Z2R2HxIu4rPx3byT263C/2Y42N6+cvNYcWs2lzazSPpsWLdBgHB4JxjpWl8WAT4ytsAn/AIlzdP8ArqtcrYow03UPlP8Aq17f7VcGMqzjiOVbW/Q9PAUacsKpPe/d90atnrlpLdxxJpkUZlOwkY6H8Kjl1yxjmdP7JhO1iM8f4Vk6YjDVLbKn/Wr296iukf7ZN8rf6xu3vXB9Yq8l/Psj0/qtL2lvLu/8zootZtLm1mkfTYsW6DAODwTjHSmWeuWkt3HEmmRRmU7CRjofwrKsUYabqHyn/Vr2/wBqotMRhqltlT/rV7e9Uq9S8fPyXch4alafl5vsYfxQ1C2uNDSCCyjgZLn7698AivK69F+IikWBJBA+1Ht9azdP8GR+JPD9rd6RItvOn7q4Wc4V2HO5fzr1sNiIwoKVTu0fLZvUpYasubRNI4yiu+tvhtNp8zXWt3EUlpboZZIoGJdwOcYOOtZ3gfR9P13xNc29zbmS3CM8aEkEfMMdPat5Y6ioSqRd1Hexw4SpDGVfZ0Xfz6HJUV9BWHwp8L3O9JrVkmQ8p5jcD86tS/B/wrHEz/Z2GBn5nbH868aXE2Ci7NS+7/gnqSy+cZcrkvx/yPnOivSPiH4R0zQdDgudPtPJeSbaG3E7hg+v0rzevcwuKhiqXtYbHNiKEsPPkk7+gV3fwkma38WySp95bckZ+orhKu6Xq97o1y1xp0vlSMu0naDx+NGMouvh50l1QYapGlWjOWyPqe1afVyXuCFt1bhF7+xqTUrN4yLy0Ox4hyOxAr5uX4i+J0GE1JlHsi/4Up+I/ikjB1RyP9wf4V8V/q1i1K6nG3bX/I9b+0KKneN0u1v+CegfGXUPt/hy0JTaVnAPPXg14vWtqvifVtatlg1G582NW3AbAOfwrJr63LMJLB4dUZd3sebjK1OrV5qasgooqzptqt7qUNs7FFkbBYDkV6LaSuzmpwlUmoR3ehWorTaLRVYgz3nBx/q1/wAaTy9F/wCe95/37X/Go9ouz+46fqkv54/+BIzaKv6lZ29tDbTWkkjxzoW/eAAjBx2qhVRkpK6MKtKVKfJLf/NXCux+Gl5FZeIppJ7dbhTbkbW7cjmuOrpvAgJ1qXAJ/cnp9RWGKk40JNG2CipYiEX3PZ4tZtLm1mkfTYsW6DAODwTjHSmWeuWkt3HEmmRRmU7CRjofwrKsUYabqHyn/Vr2/wBqotMRhqltlT/rV7e9fPKvUvHz8l3PqXhqVp+Xm+xd1LULe5lt4ILJIGjvOXXviOUUVl31rHdXQhuYy0T3ZyMkZ+SQ9RRX0GXuM6N5vW72X/BR83mUVCvaPZdTv/iTfyad46t5olVmOmMuHGR/rl/wrCu/EdzbxWzJDD++iDtle+TW98SLuKz8d28k9utwv9mONjevnLzWHFrNpc2s0j6bFi3QYBweCcY6VwYubVVxU7aHfgYJ0VJ076jbDxHc3MsivDCNkTOML3Aqr/wld3/zwg/75qzZ65aS3ccSaZFGZTsJGOh/Co5dcsY5nT+yYTtYjPH+FcbqPlT9r+DPQVKPO17H8US3fiO5t4rZkhh/fRB2yvfJosPEdzcyyK8MI2RM4wvcCnRazaXNrNI+mxYt0GAcHgnGOlMs9ctJbuOJNMijMp2EjHQ/hVe0fMn7TR+TI9kuRr2Wq816mLrMMvjWOCwu/LhhilE0hRfmYAEYH51ev/Cthe2ljbL5ltDZOHjWE4z7GqfiPxnbaDB5kOlJnzfLJVtpxz7e1IfiDoa6XHfs84heQxD90c7gMn+dclZYuTi4NyXS3c/PeJIYr66nSg1Gysl3NM6BbHxJ/bRklM/leV5efkxjHSmeHvCVtpfjpdVscRxzoVeHHRiQcj8qoWXxA0LUJJEtpJy0cTStmIj5VGTR4c8fQa14ke20+BhFCnmJM/Bbpxt/GuKtSxaozTTS5bO/Y48jpYxZhTVmls79j0PVrb7P/p9udkiH5gP4qbbTtrEoWb93FGATH/fP+FLatPq5L3BC26twi9/Y1JqVm8ZF5aHY8Q5HYgV8pdL3JfF37H6gmlanN+937eX9bHnfx1UL4fsQowBMMD8DXhde0fGXUPt/hy0JTaVnAPPXg14vX6Pw9FxwEU+7PAx8ZQqqMt7BRRRXvnAFFFFABRRRQAVoaD/yHbX/AH/6Gs+tDQOdetMf3/6VFT4H6HXgv96p/wCJfmP0eyt77WBFdzCJN3Q/xe1P8RWFrYam0dnKHU8lB/B7VA2k6iJiy2c4O7IIQ01tK1N2LPZ3DMTkkoeay09pzc2nY7fe+qOh7B81781ne3b+tPmS6j/yCdL/AOub/wDoVZtaurwyQadpkcyNG4jfKsMEfNWVWlP4fv8AzOTHJqtZ9o/+koK7D4a6hJp3iGaWJEYm3K4cZHUVx9dj8NLyKy8RTST263Cm3I2t25HNZ4l2oyd7GeEV68Va+ux61d+I7m3itmSGH99EHbK98miw8R3NzLIrwwjZEzjC9wKdFrNpc2s0j6bFi3QYBweCcY6Uyz1y0lu44k0yKMynYSMdD+FeJ7R8yftNH5M+j9kuRr2Wq816mZqGvSXsdqLtYYo0ugxYDH/LKQf1opNfvLS+hitUsY4dl4MsP4sRyUV6uElL2W9z57Mbxr2jHl0Wh1PxYBPjK2wCf+Jc3T/rqtcrYow03UPlP+rXt/tV2fxJv5NO8dW80SqzHTGXDjI/1y/4VhXfiO5t4rZkhh/fRB2yvfJrgxsaft3KUradvke1l8qv1dRjG+vftqYmmIw1S2yp/wBavb3qK6R/tk3yt/rG7e9dBYeI7m5lkV4YRsiZxhe4FVf+Eru/+eEH/fNee4UeRLm/A9NVK7qN8i27/wDAKdijDTdQ+U/6te3+1UWmIw1S2yp/1q9vetu78R3NvFbMkMP76IO2V75NFh4jubmWRXhhGyJnGF7gVfJS5ox5tvL5ke0rckpcmj8/l2OW1jS4dSllivIWkQSlgORzk0y28LaZNodzbS2hMUJEsa7jwxIBP5V0X/CV3f8Azwg/75q1d+I7m3itmSGH99EHbK98mnCUI3aqOy8v+CZ1qUqjSnSTfe66fI5DRvDGnW+pII7QqJh5MnJ5RuCKdZaLa6HqU0umW5hfLJnJPy59/pXW2HiO5uZZFeGEbImcYXuBVX/hK7v/AJ4Qf980SlGULSqN38v+CEKTjVco0Yp6dv8AISy1C9NjeMZHDRqpTAxzmmWWqahPfQxTTSGN3AYHuM1eu/EdzbxWzJDD++iDtle+TRYeI7m5lkV4YRsiZxhe4FY/VsLzJdfQt1K3LKXItfP5djz74kXE8mliOQnYtzxx9a81r1H4la3PqXh6GKaONQLgNlBz0NeXV7+XxhGhaG12fO5m5vEe+rOyCiiivQPNCiiigCzptqt7qUNs7FFkbBYDkVaaLRVYgz3nBx/q1/xpmg/8h21/3/6Gn6PZW99rAiu5hEm7of4vasJys229Ej1cLT54QjGKcpSa19I+a7ieXov/AD3vP+/a/wCNN1C1hs0tbixmlZZlLAuArLg47VN4isLWw1No7OUOp5KD+D2qPUf+QTpf/XN//QqUZX5ZJuz/AMjSvT9m61KcIqUOq/xJd/Mp/bLn/n4l/wC+zR9suf8An4l/77NQ0VvyrseV7Wp/Mx0kskpBlkZyOm5s4ptFFMhtt3YV03gQE61LgE/uT0+orma7D4a6hJp3iGaWJEYm3K4cZHUVzYpJ0JX2OrBOSxEHFXdz0WxRhpuofKf9Wvb/AGqi0xGGqW2VP+tXt71t3fiO5t4rZkhh/fRB2yvfJosPEdzcyyK8MI2RM4wvcCvnuSlzRjzbeXzPqvaVuSUuTR+fy7GFMpGpISCB9rPb/pnJRVu81qfU/skc0cahboNlBg/6qSivcwPL7H3XdXZ83mXN9Y99Wdkdh8SLuKz8d28k9utwv9mONjevnLzWHFrNpc2s0j6bFi3QYBweCcY6VpfFgE+MrbAJ/wCJc3T/AK6rXK2KMNN1D5T/AKte3+1XBjKs44jlW1v0PTwFGnLCqT3v3fdGrZ65aS3ccSaZFGZTsJGOh/Co5dcsY5nT+yYTtYjPH+FZOmIw1S2yp/1q9veorpH+2TfK3+sbt71wfWKvJfz7I9P6rS9pby7v/M6KLWbS5tZpH02LFugwDg8E4x0plnrlpLdxxJpkUZlOwkY6H8KyrFGGm6h8p/1a9v8AaqLTEYapbZU/61e3vVKvUvHz8l3IeGpWn5eb7GtLrljHM6f2TCdrEZ4/wqeLWbS5tZpH02LFugwDg8E4x0rnbpH+2TfK3+sbt71asUYabqHyn/Vr2/2qUcRUcmvXoip4akoJ+nV9/U1bPXLSW7jiTTIozKdhIx0P4VHLrljHM6f2TCdrEZ4/wrJ0xGGqW2VP+tXt71FdI/2yb5W/1jdvel9Yq8l/Psh/VaXtLeXd/wCZ0UWs2lzazSPpsWLdBgHB4JxjpTLPXLSW7jiTTIozKdhIx0P4VlWKMNN1D5T/AKte3+1UWmIw1S2yp/1q9veqVepePn5LuQ8NStPy832MP4oahbXGhpBBZRwMlz99e+ARXldei/ERSLAkggfaj2+tedV7mBk5Ubvuz5zMoRhXtHsgoooruPOCiiigDQ0DnXrTH9/+lI2k6iJiy2c4O7IIQ1f8I6fDqGrPHcIzhYyw2kgg5HpXoFr4V06SyvHeGctGilP3z8HP1rzq2KjSquPl/me5hcKq2FXN0k9n3suz7HlzaVqbsWezuGYnJJQ81Y1eGSDTtMjmRo3Eb5Vhgj5q9GsfDFhLfwRyxTlGcBh5z9M/WoLvwnpjXUge1kcKxC7pGOBn61h/aMNJNOy8vL1Op5dyxnCG8l1fmn28jyuivWLXwVoslleO9iS0aKU+ZuDn60yx8GaPLfwRy2JKM4DDc3TNbf2lS00epwf2TW11Wn/D9jyqivUZ/B2kJcSKtkdquQPmbpmp7XwVoslleO9iS0aKU+ZuDn60lmVJu1mDymso3uv6+R5PXY/DS8isvEU0k9utwptyNrduRzXSWPgzR5b+COWxJRnAYbm6ZqWDw9Y6VfzPY2zRnJTOSeM1lWzCEqT5U7s3w+V1IV1ztWWu7Ozi1m0ubWaR9NixboMA4PBOMdKZZ65aS3ccSaZFGZTsJGOh/CsqxRhpuofKf9Wvb/aqLTEYapbZU/61e3vXmqvUvHz8l3PWeGpWn5eb7F3Ur62upre3hsY4THecsuPmxFKKKoyKRqaEggfaz2/6ZyUV7uBk5Ubvuz5zMYRhXtHsjufiTfyad46t5olVmOmMuHGR/rl/wrCu/EdzbxWzJDD++iDtle+TW98SLuKz8d28k9utwv8AZjjY3r5y81hxazaXNrNI+mxYt0GAcHgnGOlceLm1VcVO2h3YGCdFSdO+o2w8R3NzLIrwwjZEzjC9wKq/8JXd/wDPCD/vmrNnrlpLdxxJpkUZlOwkY6H8Kjl1yxjmdP7JhO1iM8f4Vxuo+VP2v4M9BUo87XsfxRLd+I7m3itmSGH99EHbK98miw8R3NzLIrwwjZEzjC9wKdFrNpc2s0j6bFi3QYBweCcY6Uyz1y0lu44k0yKMynYSMdD+FV7R8yftNH5Mj2S5GvZarzXqVv8AhK7v/nhB/wB81au/EdzbxWzJDD++iDtle+TUUuuWMczp/ZMJ2sRnj/Cp4tZtLm1mkfTYsW6DAODwTjHSpjUlqva6+jKlSjpL2Onqhth4jubmWRXhhGyJnGF7gVV/4Su7/wCeEH/fNWbPXLSW7jiTTIozKdhIx0P4VHLrljHM6f2TCdrEZ4/wodR8qftfwY1Sjztex/FEt34jubeK2ZIYf30Qdsr3yaLDxHc3MsivDCNkTOML3Ap0Ws2lzazSPpsWLdBgHB4JxjpTLPXLSW7jiTTIozKdhIx0P4VXtHzJ+00fkyPZLka9lqvNepw3xK1ufUvD0MU0cagXAbKDnoa8ur1T4oahbXGhpBBZRwMlz99e+ARXldevg23S1lc8LMElX0jy6LQKKKK7DgCiiigDsPhrqEmneIZpYkRibcrhxkdRXrd34jubeK2ZIYf30Qdsr3ya8l+Gl5FZeIppJ7dbhTbkbW7cjmvXItZtLm1mkfTYsW6DAODwTjHSvGxc2qrip20PfwME6Kk6d9Rth4jubmWRXhhGyJnGF7gVV/4Su7/54Qf981Zs9ctJbuOJNMijMp2EjHQ/hUcuuWMczp/ZMJ2sRnj/AArjdR8qftfwZ6CpR52vY/iiW78R3NvFbMkMP76IO2V75NFh4jubmWRXhhGyJnGF7gU6LWbS5tZpH02LFugwDg8E4x0plnrlpLdxxJpkUZlOwkY6H8Kr2j5k/aaPyZHslyNey1XmvUrf8JXd/wDPCD/vmrV34jubeK2ZIYf30Qdsr3yail1yxjmdP7JhO1iM8f4VPFrNpc2s0j6bFi3QYBweCcY6VMaktV7XX0ZUqUdJex09UNsPEdzcyyK8MI2RM4wvcCqv/CV3f/PCD/vmrNnrlpLdxxJpkUZlOwkY6H8Kjl1yxjmdP7JhO1iM8f4UOo+VP2v4MapR52vY/iiW78R3NvFbMkMP76IO2V75NFh4jubmWRXhhGyJnGF7gU6LWbS5tZpH02LFugwDg8E4x0plnrlpLdxxJpkUZlOwkY6H8Kr2j5k/aaPyZHslyNey1XmvUzr3Wp9T+yRSpGgW6DAoOf8AVSUVJqWoW9zLbwQWSQNHecuvfEcoor18G26WsrnhY9JV9I8ui0Lvi+Wa5m0KWZ3mlk0RWd3JZmPmJkk96yrFGGm6h8p/1a9v9qtTVr7WdI1mwh1TSVsZrXSPs6B51mEqiRPm+Xp06U678R3NvFbMkMP76IO2V75NcOYxprFSlKXT13PUy2VX6soxjfXv21MTTEYapbZU/wCtXt71FdI/2yb5W/1jdveugsPEdzcyyK8MI2RM4wvcCqv/AAld3/zwg/75rzHCjyJc34HqqpXdRvkW3f8A4BTsUYabqHyn/Vr2/wBqotMRhqltlT/rV7e9bd34jubeK2ZIYf30Qdsr3yaLDxHc3MsivDCNkTOML3Aq+SlzRjzbeXzI9pW5JS5NH5/Lsc/dI/2yb5W/1jdverVijDTdQ+U/6te3+1Vz/hK7v/nhB/3zVq78R3NvFbMkMP76IO2V75NTGNG7lzfh3KlOvZQ5F9/bXsYmmIw1S2yp/wBavb3qK6R/tk3yt/rG7e9dBYeI7m5lkV4YRsiZxhe4FVf+Eru/+eEH/fNJwo8iXN+A1Uruo3yLbv8A8Ap2KMNN1D5T/q17f7VRaYjDVLbKn/Wr29627vxHc28VsyQw/vog7ZXvk0WHiO5uZZFeGEbImcYXuBV8lLmjHm28vmR7StySlyaPz+XY5bWNLh1KWWK8haRBKWA5HOTVW18FaLJZXjvYktGilPmbg5+tdT/wld3/AM8IP++atXfiO5t4rZkhh/fRB2yvfJqqc4xu41Hb/P5kVacp2UqSv69vkcTY+DNHlv4I5bElGcBhubpmsjxF4V062mhitYWtxJc+WXBJwOfX6V6bYeI7m5lkV4YRsiZxhe4Fcr4s1ufUo9PimjjUC7DZQc/dat6VV3X7xvf+tzP6vGVS0qSS0T+b9DzFotFViDPecHH+rX/Gk8vRf+e95/37X/Gl0eyt77WBFdzCJN3Q/wAXtT/EVha2GptHZyh1PJQfwe1exzLn9nd3PM9lP6q8WqcOVO3n91xzyHRDb3ekXEmLmNuZEGQAcf0qWPxnrkcckaXmFkADDYvOOfSqmo/8gnS/+ub/APoVZtONKE1zSV3qcmJqzp1OWm+VWi7Ju2qT/M3IvGOtwyrJHd4ZTkHYvB/Ktvwrrmo6vq8qXs3mjyy+AoHOR6VxFdh8NdQk07xDNLEiMTblcOMjqKxxNCiqMtEvkVhMTXeIj7zfzPRbFGGm6h8p/wBWvb/aqLTEYapbZU/61e3vW3d+I7m3itmSGH99EHbK98miw8R3NzLIrwwjZEzjC9wK8Pkpc0Y823l8z6P2lbklLk0fn8uxz90j/bJvlb/WN296tWKMNN1D5T/q17f7VXP+Eru/+eEH/fNWrvxHc28VsyQw/vog7ZXvk1MY0buXN+HcqU69lDkX39texiaYjDVLbKn/AFq9veorpH+2TfK3+sbt710Fh4jubmWRXhhGyJnGF7gVV/4Su7/54Qf980nCjyJc34DVSu6jfItu/wDwCnYow03UPlP+rXt/tVFpiMNUtsqf9avb3rbu/EdzbxWzJDD++iDtle+TRYeI7m5lkV4YRsiZxhe4FXyUuaMebby+ZHtK3JKXJo/P5djnNQkmt7jzYrdp3F3xGDgt8knc/nRU3iHVbvWdMhtxACwulZRDJ5TH5JP4u1Fe5geX2Puu6uz5vMub6x76s7I7v4kXcVn47t5J7dbhf7McbG9fOXmsOLWbS5tZpH02LFugwDg8E4x0rS+LAJ8ZW2AT/wAS5un/AF1WuVsUYabqHyn/AFa9v9quDGVZxxHKtrfoengKNOWFUnvfu+6NWz1y0lu44k0yKMynYSMdD+FRy65YxzOn9kwnaxGeP8KydMRhqltlT/rV7e9RXSP9sm+Vv9Y3b3rg+sVeS/n2R6f1Wl7S3l3f+Z0UWs2lzazSPpsWLdBgHB4JxjpTLPXLSW7jiTTIozKdhIx0P4VlWKMNN1D5T/q17f7VRaYjDVLbKn/Wr296pV6l4+fku5Dw1K0/LzfY1pdcsY5nT+yYTtYjPH+FTxazaXNrNI+mxYt0GAcHgnGOlc7dI/2yb5W/1jdverVijDTdQ+U/6te3+1SjiKjk169EVPDUlBP06vv6mrZ65aS3ccSaZFGZTsJGOh/Co5dcsY5nT+yYTtYjPH+FZOmIw1S2yp/1q9veorpH+2TfK3+sbt70vrFXkv59kP6rS9pby7v/ADOii1m0ubWaR9NixboMA4PBOMdKZZ65aS3ccSaZFGZTsJGOh/CsqxRhpuofKf8AVr2/2qi0xGGqW2VP+tXt71Sr1Lx8/JdyHhqVp+Xm+xrS65YxzOn9kwnaxGeP8Kni1m0ubWaR9NixboMA4PBOMdK4Dxtf3emW7TWjGN2uCpO3PHPrXHR+M9cjjkjS8wsgAYbF5xz6V10KWIrLnTVten/AOHE1sLQkoNO+nX/gnttnrlpLdxxJpkUZlOwkY6H8K5rxjqFvctY28FikDJe43r3wrCvNovGOtwyrJHd4ZTkHYvB/Kt/wfPN4u1yS11tjcRqhlUD5SGyOcj6mrqU61Cm6lRqy3t2+4mjisNOtFU4u+lrvs792cm2k6iJiy2c4O7IIQ01tK1N2LPZ3DMTkkoea97sPhroFzvSYTpMh5Tz34H51al+Ffh+OJnzOMDPzTvj+dcD4lw0ZWaf3f8ExlgqClytv7/8A7U8C1eGSDTtMjmRo3Eb5Vhgj5qyq9K+I/haw0bQ4Lq0gdHebYHaRmyuD0yfavNa97BYiGJo+0htdnBmEOSvbyX4JL9ArsfhpeRWXiKaSe3W4U25G1u3I5rjq6bwICdalwCf3J6fUVpipONCTRngoqWIhF9z2eLWbS5tZpH02LFugwDg8E4x0plnrlpLdxxJpkUZlOwkY6H8KyrFGGm6h8p/1a9v9qotMRhqltlT/AK1e3vXzyr1Lx8/Jdz6l4alafl5vsa0uuWMczp/ZMJ2sRnj/AAqeLWbS5tZpH02LFugwDg8E4x0rnbpH+2TfK3+sbt71asUYabqHyn/Vr2/2qUcRUcmvXoip4akoJ+nV9/U1bPXLSW7jiTTIozKdhIx0P4VHLrljHM6f2TCdrEZ4/wAKydMRhqltlT/rV7e9RXSP9sm+Vv8AWN296X1iryX8+yH9Vpe0t5d3/mdFFrNpc2s0j6bFi3QYBweCcY6Uyz1y0lu44k0yKMynYSMdD+FZVijDTdQ+U/6te3+1UWmIw1S2yp/1q9veqVepePn5LuQ8NStPy832J9cmsdWjhsW0+ONBeDcVON2I5PT3waKo308dldCe6byoluzl2HAykgor3cDJyo3fdnzmYwjCvaPZHf8AxJv5NO8dW80SqzHTGXDjI/1y/wCFYV34jubeK2ZIYf30Qdsr3ya3viRdxWfju3knt1uF/sxxsb185eaw4tZtLm1mkfTYsW6DAODwTjHSuPFzaquKnbQ7sDBOipOnfUbYeI7m5lkV4YRsiZxhe4FVf+Eru/8AnhB/3zVmz1y0lu44k0yKMynYSMdD+FRy65YxzOn9kwnaxGeP8K43UfKn7X8GegqUedr2P4olu/EdzbxWzJDD++iDtle+TRYeI7m5lkV4YRsiZxhe4FOi1m0ubWaR9NixboMA4PBOMdKZZ65aS3ccSaZFGZTsJGOh/Cq9o+ZP2mj8mR7JcjXstV5r1K3/AAld3/zwg/75q1d+I7m3itmSGH99EHbK98mopdcsY5nT+yYTtYjPH+FTxazaXNrNI+mxYt0GAcHgnGOlTGpLVe119GVKlHSXsdPVDbDxHc3MsivDCNkTOML3Aqr/AMJXd/8APCD/AL5qzZ65aS3ccSaZFGZTsJGOh/Co5dcsY5nT+yYTtYjPH+FDqPlT9r+DGqUedr2P4olu/EdzbxWzJDD++iDtle+TRYeI7m5lkV4YRsiZxhe4FOi1m0ubWaR9NixboMA4PBOMdKZZ65aS3ccSaZFGZTsJGOh/Cq9o+ZP2mj8mR7JcjXstV5r1OG+JWtz6l4ehimjjUC4DZQc9DXl1eqfFDULa40NIILKOBkufvr3wCK8rr18G26WsrnhZgkq+keXRaBXoXwX/AOR5/wC2J/mK89ru/hJM1v4tklT7y25Iz9RWOaJvBVUuxng05V4pHvWrW32f/T7c7JEPzAfxU22nbWJQs37uKMAmP++f8KW1afVyXuCFt1bhF7+xqTUrN4yLy0Ox4hyOxAr8rul7kvi79j6NNK1Ob97v28v62PO/jqoXw/YhRgCYYH4GvC69o+Muofb/AA5aEptKzgHnrwa8Xr9H4ei44CKfdngY+MoVVGW9grsPhrqEmneIZpYkRibcrhxkdRXH12Pw0vIrLxFNJPbrcKbcja3bkc16+JdqMnexjhFevFWvrsetXfiO5t4rZkhh/fRB2yvfJosPEdzcyyK8MI2RM4wvcCnRazaXNrNI+mxYt0GAcHgnGOlMs9ctJbuOJNMijMp2EjHQ/hXie0fMn7TR+TPo/ZLka9lqvNepW/4Su7/54Qf981au/EdzbxWzJDD++iDtle+TUUuuWMczp/ZMJ2sRnj/Cp4tZtLm1mkfTYsW6DAODwTjHSpjUlqva6+jKlSjpL2Onqhth4jubmWRXhhGyJnGF7gVV/wCEru/+eEH/AHzVmz1y0lu44k0yKMynYSMdD+FRy65YxzOn9kwnaxGeP8KHUfKn7X8GNUo87XsfxRLd+I7m3itmSGH99EHbK98miw8R3NzLIrwwjZEzjC9wKdFrNpc2s0j6bFi3QYBweCcY6Uyz1y0lu44k0yKMynYSMdD+FV7R8yftNH5Mj2S5GvZarzXqZGseIzcWtu1/HGsMd0GJRCT/AKuQdPxoq1qWoW9zLbwQWSQNHecuvfEcoor18G26WsrnhY9JV9I8ui0Oi+LAJ8ZW2AT/AMS5un/XVa5WxRhpuofKf9Wvb/ars/iTfyad46t5olVmOmMuHGR/rl/wrCu/EdzbxWzJDD++iDtle+TXnY2NP27lKVtO3yPWy+VX6uoxjfXv21MTTEYapbZU/wCtXt71FdI/2yb5W/1jdveugsPEdzcyyK8MI2RM4wvcCqv/AAld3/zwg/75rz3CjyJc34HpqpXdRvkW3f8A4BTsUYabqHyn/Vr2/wBqotMRhqltlT/rV7e9bd34jubeK2ZIYf30Qdsr3yaLDxHc3MsivDCNkTOML3Aq+SlzRjzbeXzI9pW5JS5NH5/Lsc/dI/2yb5W/1jdverVijDTdQ+U/6te3+1Vz/hK7v/nhB/3zVq78R3NvFbMkMP76IO2V75NTGNG7lzfh3KlOvZQ5F9/bXsYmmIw1S2yp/wBavb3qK6R/tk3yt/rG7e9dBYeI7m5lkV4YRsiZxhe4FVf+Eru/+eEH/fNJwo8iXN+A1Uruo3yLbv8A8Ap2KMNN1D5T/q17f7VRaYjDVLbKn/Wr29627vxHc28VsyQw/vog7ZXvk0WHiO5uZZFeGEbImcYXuBV8lLmjHm28vmR7StySlyaPz+XY85+IikWBJBA+1Ht9a86r1H4la3PqXh6GKaONQLgNlBz0NeXV7mA5fY+67q7PnMy5vrHvqzsgq7per3ujXLXGnS+VIy7SdoPH41SorslGM1yyV0efGUovmi7M6dfiL4nQYTUmUeyL/hSn4j+KSMHVHI/3B/hXL0VzfUcL/wA+4/cjb6zX/nf3mtqvifVtatlg1G582NW3AbAOfwrJoorohThTXLBWXkZTnOo+abuwqzY6jc6bMZbOTy3K7ScA8VWoqpRUlZijKUXzRdmbsfjPXI45I0vMLIAGGxecc+lJF4x1uGVZI7vDKcg7F4P5Vh0Vl9Xpfyr7jb6zX/nf3m03i7Wncs13kscn5B/hT4/GeuRxyRpeYWQAMNi8459KwqKPq9H+VfcH1qu1bnf3m5F4x1uGVZI7vDKcg7F4P5Vt+Fdc1HV9XlS9m80eWXwFA5yPSuIrsPhrqEmneIZpYkRibcrhxkdRXPiaFFUZaJfI6sJia7xEfeb+Z6LYow03UPlP+rXt/tVFpiMNUtsqf9avb3rbu/EdzbxWzJDD++iDtle+TRYeI7m5lkV4YRsiZxhe4FeHyUuaMebby+Z9H7StySlyaPz+XYwLlhDfK8pEaC7OWY4H3JO9FTazrSanZwR6rHbrbLdKzFhgf6uTGc+9Fe5geX2Puu6uz5vMub6x76s7I7f4kXcVn47t5J7dbhf7McbG9fOXmsOLWbS5tZpH02LFugwDg8E4x0rS+LAJ8ZW2AT/xLm6f9dVrlbFGGm6h8p/1a9v9quDGVZxxHKtrfoengKNOWFUnvfu+6NWz1y0lu44k0yKMynYSMdD+FRy65YxzOn9kwnaxGeP8KydMRhqltlT/AK1e3vUV0j/bJvlb/WN2964PrFXkv59ken9Vpe0t5d3/AJnRRazaXNrNI+mxYt0GAcHgnGOlMs9ctJbuOJNMijMp2EjHQ/hWVYow03UPlP8Aq17f7VRaYjDVLbKn/Wr296pV6l4+fku5Dw1K0/LzfY1pdcsY5nT+yYTtYjPH+FTxazaXNrNI+mxYt0GAcHgnGOlc7dI/2yb5W/1jdverVijDTdQ+U/6te3+1SjiKjk169EVPDUlBP06vv6mrZ65aS3ccSaZFGZTsJGOh/Co5dcsY5nT+yYTtYjPH+FZOmIw1S2yp/wBavb3qK6R/tk3yt/rG7e9L6xV5L+fZD+q0vaW8u7/zOii1m0ubWaR9NixboMA4PBOMdKZZ65aS3ccSaZFGZTsJGOh/CsqxRhpuofKf9Wvb/aqLTEYapbZU/wCtXt71Sr1Lx8/JdyHhqVp+Xm+xh/FDULa40NIILKOBkufvr3wCK8rr2LWNLh1KWWK8haRBKWA5HOTVW18FaLJZXjvYktGilPmbg5+td+Gx8YR5Jp31PMxeWznPng1bTds8nor1Wx8GaPLfwRy2JKM4DDc3TNRz+DtIS4kVbI7VcgfM3TNdH9pUuW9mc39kV+bluv6+R5dRXrFr4K0WSyvHexJaNFKfM3Bz9aZY+DNHlv4I5bElGcBhubpmn/aVLTR6i/smtrqtP+H7HlVFeoz+DtIS4kVbI7VcgfM3TNT2vgrRZLK8d7Elo0Up8zcHP1pLMqTdrMHlNZRvdf18jyeivVbHwZo8t/BHLYkozgMNzdM1HP4O0hLiRVsjtVyB8zdM0f2lS5b2Y/7Ir83Ldf18jy6ivWLXwVoslleO9iS0aKU+ZuDn60yx8GaPLfwRy2JKM4DDc3TNP+0qWmj1F/ZNbXVaf8P2PKqK9Rn8HaQlxIq2R2q5A+ZumantfBWiyWV472JLRopT5m4OfrSWZUm7WYPKayje6/r5Hk9dj8NLyKy8RTST263Cm3I2t25HNdJY+DNHlv4I5bElGcBhubpmpYPD1jpV/M9jbNGclM5J4zWVbMISpPlTuzfD5XUhXXO1Za7s7OLWbS5tZpH02LFugwDg8E4x0plnrlpLdxxJpkUZlOwkY6H8KyrFGGm6h8p/1a9v9qotMRhqltlT/rV7e9eaq9S8fPyXc9Z4alafl5vsW9Wu7O+aC1XT4owl58xwDuxHJ2x+NFUplI1JCQQPtZ7f9M5KK93AycqN33Z85mMIwr2j2R3XxJv5NO8dW80SozHTGXDjI/1y/wCFYV34jubeK2ZIYf30Qdsr3ya3viPdxWXju3knt1uFOmONjf8AXZeaw4tZtLm1mkfTYsW6DAODwTjHSuPFzaquKnbQ7sDBOipOnfUbYeI7m5lkV4YRsiZxhe4FVf8AhK7v/nhB/wB81Zs9ctJbuOJNMijMp2EjHQ/hUcuuWMczp/ZMJ2sRnj/CuN1Hyp+1/BnoKlHna9j+KJbvxHc28VsyQw/vog7ZXvk0WHiO5uZZFeGEbImcYXuBTotZtLm1mkfTYsW6DAODwTjHSmWeuWkt3HEmmRRmU7CRjofwqvaPmT9po/JkeyXI17LVea9St/wld3/zwg/75q1d+I7m3itmSGH99EHbK98mopdcsY5nT+yYTtYjPH+FTxazaXNrNI+mxYt0GAcHgnGOlTGpLVe119GVKlHSXsdPVDbDxHc3MsivDCNkTOML3Aqr/wAJXd/88IP++as2euWkt3HEmmRRmU7CRjofwqOXXLGOZ0/smE7WIzx/hQ6j5U/a/gxqlHna9j+KJbvxHc28VsyQw/vog7ZXvk0WHiO5uZZFeGEbImcYXuBTotZtLm1mkfTYsW6DAODwTjHSmWeuWkt3HEmmRRmU7CRjofwqvaPmT9po/JkeyXI17LVea9St/wAJXd/88IP++atXfiO5t4rZkhh/fRB2yvfJqKXXLGOZ0/smE7WIzx/hU8Ws2lzazSPpsWLdBgHB4JxjpUxqS1XtdfRlSpR0l7HT1Q2w8R3NzLIrwwjZEzjC9wKq/wDCV3f/ADwg/wC+as2euWkt3HEmmRRmU7CRjofwqOXXLGOZ0/smE7WIzx/hQ6j5U/a/gxqlHna9j+KJbvxHc28VsyQw/vog7ZXvk0WHiO5uZZFeGEbImcYXuBTotZtLm1mkfTYsW6DAODwTjHSmWeuWkt3HEmmRRmU7CRjofwqvaPmT9po/JkeyXI17LVea9St/wld3/wA8IP8AvmrV34jubeK2ZIYf30Qdsr3yail1yxjmdP7JhO1iM8f4VPFrNpc2s0j6bFi3QYBweCcY6VMaktV7XX0ZUqUdJex09UNsPEdzcyyK8MI2RM4wvcCqv/CV3f8Azwg/75qzZ65aS3ccSaZFGZTsJGOh/Co5dcsY5nT+yYTtYjPH+FDqPlT9r+DGqUedr2P4olu/EdzbxWzJDD++iDtle+TRYeI7m5lkV4YRsiZxhe4FOi1m0ubWaR9NixboMA4PBOMdKZZ65aS3ccSaZFGZTsJGOh/Cq9o+ZP2mj8mR7JcjXstV5r1K3/CV3f8Azwg/75q1d+I7m3itmSGH99EHbK98mopdcsY5nT+yYTtYjPH+FTxazaXNrNI+mxYt0GAcHgnGOlTGpLVe119GVKlHSXsdPVDbDxHc3MsivDCNkTOML3Aqr/wld3/zwg/75qzZ65aS3ccSaZFGZTsJGOh/Co5dcsY5nT+yYTtYjPH+FDqPlT9r+DGqUedr2P4olu/EdzbxWzJDD++iDtle+TRYeI7m5lkV4YRsiZxhe4FOi1m0ubWaR9NixboMA4PBOMdKZZ65aS3ccSaZFGZTsJGOh/Cq9o+ZP2mj8mR7JcjXstV5r1MnVtUuNbtre1dhbf6UGEkAww/dyetFP1ye11SOKyitvsm28GZYG2scRydxRXr4Nt0tZXPCx6Sr6R5dFobPx0vJ7HxZp72rBGezZWygbI357g+grzRPEmqRxyIk6BZAA48iPn/x2iiuiVKnJ3lFN+hyxrVYLljJpeokfiLU4ZVkjnRXU5B8iPg/980jeINSdyzTRksck+RH/wDE0UVPsKNrcq+5F/Wa9787+9jk8SapHHIiToFkADjyI+f/AB2kj8RanDKskc6K6nIPkR8H/vmiij2FL+VfchfWa/8AO/vYjeINSdyzTRksck+RH/8AE05PEmqRxyIk6BZAA48iPn/x2iij2FL+Vfcg+s17W5397Ej8RanDKskc6K6nIPkR8H/vmkbxBqTuWaaMljknyI//AImiij2FG1uVfch/Wa9787+9jk8SapHHIiToFkADjyI+f/HaSPxFqcMqyRzorqcg+RHwf++aKKPYUv5V9yF9Zr/zv72I3iDUncs00ZLHJPkR/wDxNOTxJqkcciJOgWQAOPIj5/8AHaKKPYUv5V9yD6zXtbnf3sSPxFqcMqyRzorqcg+RHwf++aRvEGpO5ZpoyWOSfIj/APiaKKPYUbW5V9yH9Zr3vzv72OTxJqkcciJOgWQAOPIj5/8AHaSPxFqcMqyRzorqcg+RHwf++aKKPYUv5V9yF9Zr/wA7+9iN4g1J3LNNGSxyT5Ef/wATTk8SapHHIiToFkADjyI+f/HaKKPYUv5V9yD6zXtbnf3sSPxFqcMqyRzorqcg+RHwf++aRvEGpO5ZpoyWOSfIj/8AiaKKPYUbW5V9yH9Zr3vzv72OTxJqkcciJOgWQAOPIj5/8dpI/EWpwyrJHOiupyD5EfB/75ooo9hS/lX3IX1mv/O/vYjeINSdyzTRksck+RH/APE05PEmqRxyIk6BZAA48iPn/wAdooo9hS/lX3IPrNe1ud/exI/EWpwyrJHOiupyD5EfB/75pG8Qak7lmmjJY5J8iP8A+Jooo9hRtblX3If1mve/O/vY5PEmqRxyIk6BZAA48iPn/wAdpI/EWpwyrJHOiupyD5EfB/75ooo9hS/lX3IX1mv/ADv72XNJ1a9v9agjupVdS7OcRKuW2NzwB6miiitIxjFWirGUpym7yd2f/9k="
    }
   },
   "cell_type": "markdown",
   "id": "437698b0",
   "metadata": {},
   "source": [
    "![three_box_env.JPG](attachment:three_box_env.JPG)"
   ]
  },
  {
   "attachments": {
    "4_box_env.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "347b8756",
   "metadata": {},
   "source": [
    "![4_box_env.png](attachment:4_box_env.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7ff65ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # We need to save the exact one we see below so comment this when selected the desired env topology\n",
    "# initial_agent_position = game_env.player_position\n",
    "# initial_box_mapping = game_env.box_mapping\n",
    "# initial_room_fixed = game_env.room_fixed\n",
    "# initial_room_state = game_env.room_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aa91626d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 Box environment\n",
    "initial_room_state = np.array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "                               [0, 0, 0, 0, 1, 1, 1, 0, 0, 0],\n",
    "                               [0, 0, 1, 1, 1, 4, 1, 1, 1, 0],\n",
    "                               [0, 0, 5, 4, 1, 1, 1, 2, 1, 0],\n",
    "                               [0, 0, 0, 0, 1, 1, 2, 1, 1, 0],\n",
    "                               [0, 0, 0, 0, 1, 1, 0, 0, 0, 0],\n",
    "                               [0, 0, 0, 0, 0, 2, 1, 0, 0, 0],\n",
    "                               [0, 0, 0, 0, 1, 4, 1, 0, 0, 0],\n",
    "                               [0, 0, 0, 0, 1, 1, 1, 1, 1, 0],\n",
    "                               [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
    "\n",
    "initial_room_fixed = np.array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "                               [0, 0, 0, 0, 1, 1, 1, 0, 0, 0],\n",
    "                               [0, 0, 1, 1, 1, 1, 1, 1, 1, 0],\n",
    "                               [0, 0, 1, 1, 1, 1, 1, 2, 1, 0],\n",
    "                               [0, 0, 0, 0, 1, 1, 2, 1, 1, 0],\n",
    "                               [0, 0, 0, 0, 1, 1, 0, 0, 0, 0],\n",
    "                               [0, 0, 0, 0, 0, 2, 1, 0, 0, 0],\n",
    "                               [0, 0, 0, 0, 1, 1, 1, 0, 0, 0],\n",
    "                               [0, 0, 0, 0, 1, 1, 1, 1, 1, 0],\n",
    "                               [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
    "\n",
    "initial_box_mapping = np.array({(3, 7): (7, 5), (4, 6): (3, 3), (6, 5): (2, 5)})\n",
    "\n",
    "initial_agent_position = np.array([3,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2ef58c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 4 Box environment\n",
    "# initial_room_state = np.array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "#        [0, 0, 0, 0, 2, 1, 1, 1, 1, 0],\n",
    "#        [0, 0, 0, 5, 4, 1, 0, 4, 1, 0],\n",
    "#        [0, 0, 0, 0, 2, 1, 0, 1, 1, 0],\n",
    "#        [0, 0, 0, 1, 4, 1, 1, 0, 0, 0],\n",
    "#        [0, 0, 0, 0, 2, 2, 0, 0, 0, 0],\n",
    "#        [0, 0, 0, 1, 1, 1, 0, 0, 0, 0],\n",
    "#        [0, 0, 0, 1, 4, 1, 0, 0, 0, 0],\n",
    "#        [0, 0, 0, 1, 1, 1, 0, 0, 0, 0],\n",
    "#        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
    "\n",
    "# initial_room_fixed = np.array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "#        [0, 0, 0, 0, 2, 1, 1, 1, 1, 0],\n",
    "#        [0, 0, 0, 1, 1, 1, 0, 1, 1, 0],\n",
    "#        [0, 0, 0, 0, 2, 1, 0, 1, 1, 0],\n",
    "#        [0, 0, 0, 1, 1, 1, 1, 0, 0, 0],\n",
    "#        [0, 0, 0, 0, 2, 2, 0, 0, 0, 0],\n",
    "#        [0, 0, 0, 1, 1, 1, 0, 0, 0, 0],\n",
    "#        [0, 0, 0, 1, 1, 1, 0, 0, 0, 0],\n",
    "#        [0, 0, 0, 1, 1, 1, 0, 0, 0, 0],\n",
    "#        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
    "\n",
    "# initial_box_mapping = np.array({(1, 4): (2, 7), (3, 4): (4, 4), (5, 4): (7, 4), (5, 5): (2, 4)})\n",
    "\n",
    "# initial_agent_position = np.array([2, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0bda640e",
   "metadata": {},
   "outputs": [],
   "source": [
    "game_env = my_sokoban_env(initial_agent_position=initial_agent_position,\n",
    "                        initial_box_mapping=initial_box_mapping,\n",
    "                        initial_room_fixed=initial_room_fixed,\n",
    "                        initial_room_state=initial_room_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1a24c97c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# game_env.reset()\n",
    "# game_env.render(mode='human')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bd7f6935",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install stable-baselines3 gym numpy torch torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "de992078",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install shimmy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c243e2bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "116ef754",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install mcts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "61e55537",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from stable_baselines3 import DQN\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from tqdm import tqdm\n",
    "\n",
    "from stable_baselines3.common.atari_wrappers import AtariWrapper\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from stable_baselines3.dqn import CnnPolicy, MlpPolicy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "da5da7a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_sokoban():\n",
    "    # Create the Sokoban environment\n",
    "    env = my_sokoban_env(initial_agent_position=initial_agent_position,\n",
    "                        initial_box_mapping=initial_box_mapping,\n",
    "                        initial_room_fixed=initial_room_fixed,\n",
    "                        initial_room_state=initial_room_state)\n",
    "\n",
    "    # Wrap the environment with DummyVecEnv to support training with DQN\n",
    "    env = DummyVecEnv([lambda: env])\n",
    "\n",
    "    # Define and train the DQN model\n",
    "    model = DQN(\"MlpPolicy\", env, buffer_size=50000,learning_starts=5000, verbose=1)\n",
    "\n",
    "    # Use the modified second_reset function for resetting the environment\n",
    "    model.set_env(env)\n",
    "    model.learn(total_timesteps=20000)\n",
    "\n",
    "    # Save the trained model\n",
    "    model.save(\"sokoban_dqn_model_ml\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "803dcc11",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'support_multi_env'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m----> 2\u001b[0m     \u001b[43mtrain_sokoban\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[30], line 12\u001b[0m, in \u001b[0;36mtrain_sokoban\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m env \u001b[38;5;241m=\u001b[39m DummyVecEnv([\u001b[38;5;28;01mlambda\u001b[39;00m: env])\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Define and train the DQN model\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mDQN\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mMlpPolicy\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-3\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgamma\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.99\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtau\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1.0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtarget_update_interval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexploration_fraction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.05\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[43m            \u001b[49m\u001b[43mexploration_initial_eps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1.0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexploration_final_eps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtrain_freq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreplay_buffer_class\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreplay_buffer_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimize_memory_usage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpolicy_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensorboard_log\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mauto\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[43m            \u001b[49m\u001b[43msupport_multi_env\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_sde\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msde_sample_freq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[43m            \u001b[49m\u001b[43muse_sde_at_warmup\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# Use the modified second_reset function for resetting the environment\u001b[39;00m\n\u001b[0;32m     23\u001b[0m model\u001b[38;5;241m.\u001b[39mset_env(env)\n",
      "\u001b[1;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'support_multi_env'"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    train_sokoban()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "247df444",
   "metadata": {},
   "source": [
    "**rollout/exploration_rate:** This is the current rate of exploration used by the agent. In the beginning, the agent needs to explore the environment to learn as much as possible. As the training progresses and the agent gets more familiar with the environment, it relies less on exploration and more on the knowledge it has already gained. The exploration rate usually starts high and decreases over time. The actual value (0.088) can be interpreted as the chance (8.8%) that the agent will take a random action instead of using the policy it has learned.\n",
    "\n",
    "**ime/episodes:** This is the number of episodes that have been completed so far during training. An episode is one sequence of states, actions and rewards, which ends with a terminal state (e.g., the game is over). In this case, 8 episodes have been completed.\n",
    "\n",
    "**time/fps:** This stands for frames per second, indicating how many steps are being processed per second in the environment. High fps leads to faster training. Here, it shows that your model is processing 90 steps per second.\n",
    "\n",
    "**time/time_elapsed:** This is the total time (in seconds) that has elapsed since the training started. In this case, it's been 10 seconds.\n",
    "\n",
    "**time/total_timesteps:** This is the total number of timesteps that have been processed so far. A timestep is one step in the environment, and it's not necessarily equivalent to a real-time second. Here, your model has processed a total of 960 timesteps since the beginning of training.\n",
    "\n",
    "**train/learning_rate:** This is the learning rate used by the optimizer during the training of the DQN. The learning rate dictates how much the model parameters are updated in response to the observed error in each training step.\n",
    "\n",
    "**train/loss:** This metric represents the value of the loss function, which the algorithm is trying to minimize. It's a measure of the difference between the model's predictions and the actual data. Lower values generally indicate better performance, although overfitting can occur if the loss becomes too low.\n",
    "\n",
    "**train/n_updates:** This is the number of times the model has been updated during the training process. In the context of DQN, this would be the number of optimization steps taken."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e8c6fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_sokoban(model, num_episodes=100):\n",
    "    # Create the Sokoban environment\n",
    "    env = my_sokoban_env(initial_agent_position=initial_agent_position,\n",
    "                        initial_box_mapping=initial_box_mapping,\n",
    "                        initial_room_fixed=initial_room_fixed,\n",
    "                        initial_room_state=initial_room_state)\n",
    "\n",
    "    for episode in range(num_episodes):\n",
    "        obs = env.reset()\n",
    "        done = False\n",
    "        total_reward = 0\n",
    "\n",
    "        while not done:\n",
    "            # the model requires input of shape (num_parallel_envs, obs_dim)\n",
    "            # so we expand the first dimension\n",
    "            action, _ = model.predict(np.expand_dims(obs, axis=0))\n",
    "            obs, reward, done, info = env.step(action[0])\n",
    "            total_reward += reward\n",
    "            \n",
    "            \n",
    "        print(f\"Episode {episode + 1}: {total_reward}\")\n",
    "        \n",
    "        env.render(mode='human')\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    model = DQN.load(\"sokoban_dqn_model_ml\")\n",
    "    test_sokoban(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8eeb1cd",
   "metadata": {},
   "source": [
    "# Implement PPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3fa0dd83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip uninstall torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7008b205",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\lalep\\anaconda3\\lib\\site-packages (2.0.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\lalep\\anaconda3\\lib\\site-packages (from torch) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\lalep\\anaconda3\\lib\\site-packages (from torch) (4.5.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\lalep\\anaconda3\\lib\\site-packages (from torch) (1.11.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\lalep\\anaconda3\\lib\\site-packages (from torch) (2.8.4)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\lalep\\anaconda3\\lib\\site-packages (from torch) (3.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\lalep\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\lalep\\anaconda3\\lib\\site-packages (from sympy->torch) (1.2.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8503693e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env in a VecTransposeImage.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Calling torch.geqrf on a CPU tensor requires compiling PyTorch with LAPACK. Please use PyTorch built with LAPACK support.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[41], line 23\u001b[0m\n\u001b[0;32m     20\u001b[0m     model\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msokoban_ppo_model\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m---> 23\u001b[0m     \u001b[43mtrain_sokoban\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[41], line 15\u001b[0m, in \u001b[0;36mtrain_sokoban\u001b[1;34m()\u001b[0m\n\u001b[0;32m     12\u001b[0m env \u001b[38;5;241m=\u001b[39m DummyVecEnv([\u001b[38;5;28;01mlambda\u001b[39;00m: env])\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Define and train the PPO model\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mPPO\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mMlpPolicy\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m model\u001b[38;5;241m.\u001b[39mlearn(total_timesteps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20000\u001b[39m)\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Save the trained model\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\stable_baselines3\\ppo\\ppo.py:164\u001b[0m, in \u001b[0;36mPPO.__init__\u001b[1;34m(self, policy, env, learning_rate, n_steps, batch_size, n_epochs, gamma, gae_lambda, clip_range, clip_range_vf, normalize_advantage, ent_coef, vf_coef, max_grad_norm, use_sde, sde_sample_freq, target_kl, stats_window_size, tensorboard_log, policy_kwargs, verbose, seed, device, _init_setup_model)\u001b[0m\n\u001b[0;32m    161\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_kl \u001b[38;5;241m=\u001b[39m target_kl\n\u001b[0;32m    163\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _init_setup_model:\n\u001b[1;32m--> 164\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_setup_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\stable_baselines3\\ppo\\ppo.py:167\u001b[0m, in \u001b[0;36mPPO._setup_model\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    166\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_setup_model\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 167\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_setup_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    169\u001b[0m     \u001b[38;5;66;03m# Initialize schedules for policy/value clipping\u001b[39;00m\n\u001b[0;32m    170\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclip_range \u001b[38;5;241m=\u001b[39m get_schedule_fn(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclip_range)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\stable_baselines3\\common\\on_policy_algorithm.py:123\u001b[0m, in \u001b[0;36mOnPolicyAlgorithm._setup_model\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrollout_buffer \u001b[38;5;241m=\u001b[39m buffer_cls(\n\u001b[0;32m    114\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_steps,\n\u001b[0;32m    115\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobservation_space,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    120\u001b[0m     n_envs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_envs,\n\u001b[0;32m    121\u001b[0m )\n\u001b[0;32m    122\u001b[0m \u001b[38;5;66;03m# pytype:disable=not-instantiable\u001b[39;00m\n\u001b[1;32m--> 123\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpolicy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpolicy_class(  \u001b[38;5;66;03m# type: ignore[assignment]\u001b[39;00m\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobservation_space, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maction_space, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlr_schedule, use_sde\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_sde, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpolicy_kwargs\n\u001b[0;32m    125\u001b[0m )\n\u001b[0;32m    126\u001b[0m \u001b[38;5;66;03m# pytype:enable=not-instantiable\u001b[39;00m\n\u001b[0;32m    127\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpolicy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpolicy\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\stable_baselines3\\common\\policies.py:507\u001b[0m, in \u001b[0;36mActorCriticPolicy.__init__\u001b[1;34m(self, observation_space, action_space, lr_schedule, net_arch, activation_fn, ortho_init, use_sde, log_std_init, full_std, use_expln, squash_output, features_extractor_class, features_extractor_kwargs, share_features_extractor, normalize_images, optimizer_class, optimizer_kwargs)\u001b[0m\n\u001b[0;32m    504\u001b[0m \u001b[38;5;66;03m# Action distribution\u001b[39;00m\n\u001b[0;32m    505\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maction_dist \u001b[38;5;241m=\u001b[39m make_proba_distribution(action_space, use_sde\u001b[38;5;241m=\u001b[39muse_sde, dist_kwargs\u001b[38;5;241m=\u001b[39mdist_kwargs)\n\u001b[1;32m--> 507\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_build\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlr_schedule\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\stable_baselines3\\common\\policies.py:603\u001b[0m, in \u001b[0;36mActorCriticPolicy._build\u001b[1;34m(self, lr_schedule)\u001b[0m\n\u001b[0;32m    600\u001b[0m         module_gains[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvf_features_extractor] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msqrt(\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m    602\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module, gain \u001b[38;5;129;01min\u001b[39;00m module_gains\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m--> 603\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minit_weights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgain\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    605\u001b[0m \u001b[38;5;66;03m# Setup optimizer with initial learning rate\u001b[39;00m\n\u001b[0;32m    606\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer_class(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39mlr_schedule(\u001b[38;5;241m1\u001b[39m), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer_kwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:884\u001b[0m, in \u001b[0;36mModule.apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    849\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Applies ``fn`` recursively to every submodule (as returned by ``.children()``)\u001b[39;00m\n\u001b[0;32m    850\u001b[0m \u001b[38;5;124;03mas well as self. Typical use includes initializing the parameters of a model\u001b[39;00m\n\u001b[0;32m    851\u001b[0m \u001b[38;5;124;03m(see also :ref:`nn-init-doc`).\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    881\u001b[0m \n\u001b[0;32m    882\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    883\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[1;32m--> 884\u001b[0m     \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    885\u001b[0m fn(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m    886\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:884\u001b[0m, in \u001b[0;36mModule.apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    849\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Applies ``fn`` recursively to every submodule (as returned by ``.children()``)\u001b[39;00m\n\u001b[0;32m    850\u001b[0m \u001b[38;5;124;03mas well as self. Typical use includes initializing the parameters of a model\u001b[39;00m\n\u001b[0;32m    851\u001b[0m \u001b[38;5;124;03m(see also :ref:`nn-init-doc`).\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    881\u001b[0m \n\u001b[0;32m    882\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    883\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[1;32m--> 884\u001b[0m     \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    885\u001b[0m fn(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m    886\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:885\u001b[0m, in \u001b[0;36mModule.apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    883\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m    884\u001b[0m     module\u001b[38;5;241m.\u001b[39mapply(fn)\n\u001b[1;32m--> 885\u001b[0m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    886\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\stable_baselines3\\common\\policies.py:306\u001b[0m, in \u001b[0;36mBasePolicy.init_weights\u001b[1;34m(module, gain)\u001b[0m\n\u001b[0;32m    302\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    303\u001b[0m \u001b[38;5;124;03mOrthogonal initialization (used in PPO and A2C)\u001b[39;00m\n\u001b[0;32m    304\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(module, (nn\u001b[38;5;241m.\u001b[39mLinear, nn\u001b[38;5;241m.\u001b[39mConv2d)):\n\u001b[1;32m--> 306\u001b[0m     \u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minit\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43morthogonal_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgain\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    307\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m module\u001b[38;5;241m.\u001b[39mbias \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    308\u001b[0m         module\u001b[38;5;241m.\u001b[39mbias\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mfill_(\u001b[38;5;241m0.0\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\init.py:484\u001b[0m, in \u001b[0;36morthogonal_\u001b[1;34m(tensor, gain)\u001b[0m\n\u001b[0;32m    481\u001b[0m     flattened\u001b[38;5;241m.\u001b[39mt_()\n\u001b[0;32m    483\u001b[0m \u001b[38;5;66;03m# Compute the qr factorization\u001b[39;00m\n\u001b[1;32m--> 484\u001b[0m q, r \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinalg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mqr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mflattened\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    485\u001b[0m \u001b[38;5;66;03m# Make Q uniform according to https://arxiv.org/pdf/math-ph/0609050.pdf\u001b[39;00m\n\u001b[0;32m    486\u001b[0m d \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdiag(r, \u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Calling torch.geqrf on a CPU tensor requires compiling PyTorch with LAPACK. Please use PyTorch built with LAPACK support."
     ]
    }
   ],
   "source": [
    "from stable_baselines3 import PPO\n",
    "# from stable_baselines3.common.envs import DummyVecEnv\n",
    "\n",
    "def train_sokoban():\n",
    "    # Create the Sokoban environment\n",
    "    env = my_sokoban_env(initial_agent_position=initial_agent_position,\n",
    "                        initial_box_mapping=initial_box_mapping,\n",
    "                        initial_room_fixed=initial_room_fixed,\n",
    "                        initial_room_state=initial_room_state)\n",
    "\n",
    "    # Wrap the environment with DummyVecEnv to support training with PPO\n",
    "    env = DummyVecEnv([lambda: env])\n",
    "\n",
    "    # Define and train the PPO model\n",
    "    model = PPO(\"MlpPolicy\", env, n_steps=128, batch_size=128, verbose=1)\n",
    "\n",
    "    model.learn(total_timesteps=20000)\n",
    "\n",
    "    # Save the trained model\n",
    "    model.save(\"sokoban_ppo_model\")\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    train_sokoban()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5325b87c",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'sokoban_ppo_model.zip'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[38], line 22\u001b[0m\n\u001b[0;32m     19\u001b[0m         env\u001b[38;5;241m.\u001b[39mrender()\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m---> 22\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mPPO\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msokoban_ppo_model\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     23\u001b[0m     test_sokoban(model)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\stable_baselines3\\common\\base_class.py:679\u001b[0m, in \u001b[0;36mBaseAlgorithm.load\u001b[1;34m(cls, path, env, device, custom_objects, print_system_info, force_reset, **kwargs)\u001b[0m\n\u001b[0;32m    676\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m== CURRENT SYSTEM INFO ==\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    677\u001b[0m     get_system_info()\n\u001b[1;32m--> 679\u001b[0m data, params, pytorch_variables \u001b[38;5;241m=\u001b[39m \u001b[43mload_from_zip_file\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    680\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    681\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    682\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_objects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    683\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprint_system_info\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprint_system_info\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    684\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    686\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo data found in the saved file\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    687\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m params \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo params found in the saved file\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\stable_baselines3\\common\\save_util.py:390\u001b[0m, in \u001b[0;36mload_from_zip_file\u001b[1;34m(load_path, load_data, custom_objects, device, verbose, print_system_info)\u001b[0m\n\u001b[0;32m    363\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_from_zip_file\u001b[39m(\n\u001b[0;32m    364\u001b[0m     load_path: Union[\u001b[38;5;28mstr\u001b[39m, pathlib\u001b[38;5;241m.\u001b[39mPath, io\u001b[38;5;241m.\u001b[39mBufferedIOBase],\n\u001b[0;32m    365\u001b[0m     load_data: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    369\u001b[0m     print_system_info: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    370\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[Optional[Dict[\u001b[38;5;28mstr\u001b[39m, Any]], TensorDict, Optional[TensorDict]]:\n\u001b[0;32m    371\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    372\u001b[0m \u001b[38;5;124;03m    Load model data from a .zip archive\u001b[39;00m\n\u001b[0;32m    373\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    388\u001b[0m \u001b[38;5;124;03m        and dict of pytorch variables\u001b[39;00m\n\u001b[0;32m    389\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 390\u001b[0m     load_path \u001b[38;5;241m=\u001b[39m \u001b[43mopen_path\u001b[49m\u001b[43m(\u001b[49m\u001b[43mload_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msuffix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mzip\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    392\u001b[0m     \u001b[38;5;66;03m# set device to cpu if cuda is not available\u001b[39;00m\n\u001b[0;32m    393\u001b[0m     device \u001b[38;5;241m=\u001b[39m get_device(device\u001b[38;5;241m=\u001b[39mdevice)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\functools.py:888\u001b[0m, in \u001b[0;36msingledispatch.<locals>.wrapper\u001b[1;34m(*args, **kw)\u001b[0m\n\u001b[0;32m    884\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m args:\n\u001b[0;32m    885\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfuncname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m requires at least \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    886\u001b[0m                     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m1 positional argument\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m--> 888\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m dispatch(args[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\stable_baselines3\\common\\save_util.py:234\u001b[0m, in \u001b[0;36mopen_path_str\u001b[1;34m(path, mode, verbose, suffix)\u001b[0m\n\u001b[0;32m    219\u001b[0m \u001b[38;5;129m@open_path\u001b[39m\u001b[38;5;241m.\u001b[39mregister(\u001b[38;5;28mstr\u001b[39m)\n\u001b[0;32m    220\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mopen_path_str\u001b[39m(path: \u001b[38;5;28mstr\u001b[39m, mode: \u001b[38;5;28mstr\u001b[39m, verbose: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m, suffix: Optional[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m io\u001b[38;5;241m.\u001b[39mBufferedIOBase:\n\u001b[0;32m    221\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    222\u001b[0m \u001b[38;5;124;03m    Open a path given by a string. If writing to the path, the function ensures\u001b[39;00m\n\u001b[0;32m    223\u001b[0m \u001b[38;5;124;03m    that the path exists.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    232\u001b[0m \u001b[38;5;124;03m    :return:\u001b[39;00m\n\u001b[0;32m    233\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 234\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mopen_path\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpathlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msuffix\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\functools.py:888\u001b[0m, in \u001b[0;36msingledispatch.<locals>.wrapper\u001b[1;34m(*args, **kw)\u001b[0m\n\u001b[0;32m    884\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m args:\n\u001b[0;32m    885\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfuncname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m requires at least \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    886\u001b[0m                     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m1 positional argument\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m--> 888\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m dispatch(args[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\stable_baselines3\\common\\save_util.py:286\u001b[0m, in \u001b[0;36mopen_path_pathlib\u001b[1;34m(path, mode, verbose, suffix)\u001b[0m\n\u001b[0;32m    279\u001b[0m         path\u001b[38;5;241m.\u001b[39mparent\u001b[38;5;241m.\u001b[39mmkdir(exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, parents\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    281\u001b[0m \u001b[38;5;66;03m# if opening was successful uses the identity function\u001b[39;00m\n\u001b[0;32m    282\u001b[0m \u001b[38;5;66;03m# if opening failed with IsADirectory|FileNotFound, calls open_path_pathlib\u001b[39;00m\n\u001b[0;32m    283\u001b[0m \u001b[38;5;66;03m#   with corrections\u001b[39;00m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;66;03m# if reading failed with FileNotFoundError, calls open_path_pathlib with suffix\u001b[39;00m\n\u001b[1;32m--> 286\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mopen_path\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msuffix\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\functools.py:888\u001b[0m, in \u001b[0;36msingledispatch.<locals>.wrapper\u001b[1;34m(*args, **kw)\u001b[0m\n\u001b[0;32m    884\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m args:\n\u001b[0;32m    885\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfuncname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m requires at least \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    886\u001b[0m                     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m1 positional argument\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m--> 888\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m dispatch(args[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\stable_baselines3\\common\\save_util.py:266\u001b[0m, in \u001b[0;36mopen_path_pathlib\u001b[1;34m(path, mode, verbose, suffix)\u001b[0m\n\u001b[0;32m    264\u001b[0m             path, suffix \u001b[38;5;241m=\u001b[39m newpath, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    265\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 266\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m error\n\u001b[0;32m    267\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    268\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\stable_baselines3\\common\\save_util.py:258\u001b[0m, in \u001b[0;36mopen_path_pathlib\u001b[1;34m(path, mode, verbose, suffix)\u001b[0m\n\u001b[0;32m    256\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    257\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 258\u001b[0m         path \u001b[38;5;241m=\u001b[39m \u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    259\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m error:\n\u001b[0;32m    260\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m suffix \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m suffix \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\pathlib.py:1252\u001b[0m, in \u001b[0;36mPath.open\u001b[1;34m(self, mode, buffering, encoding, errors, newline)\u001b[0m\n\u001b[0;32m   1246\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mopen\u001b[39m(\u001b[38;5;28mself\u001b[39m, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m, buffering\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1247\u001b[0m          errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m   1248\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1249\u001b[0m \u001b[38;5;124;03m    Open the file pointed by this path and return a file object, as\u001b[39;00m\n\u001b[0;32m   1250\u001b[0m \u001b[38;5;124;03m    the built-in open() function does.\u001b[39;00m\n\u001b[0;32m   1251\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1252\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffering\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnewline\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1253\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mopener\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_opener\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\pathlib.py:1120\u001b[0m, in \u001b[0;36mPath._opener\u001b[1;34m(self, name, flags, mode)\u001b[0m\n\u001b[0;32m   1118\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_opener\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, flags, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0o666\u001b[39m):\n\u001b[0;32m   1119\u001b[0m     \u001b[38;5;66;03m# A stub for the opener argument to built-in open()\u001b[39;00m\n\u001b[1;32m-> 1120\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_accessor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'sokoban_ppo_model.zip'"
     ]
    }
   ],
   "source": [
    "def test_sokoban():\n",
    "    # Load the trained model\n",
    "#     model = PPO.load(\"sokoban_ppo_model\")\n",
    "\n",
    "    # Create the Sokoban environment\n",
    "    env = my_sokoban_env(initial_agent_position=initial_agent_position,\n",
    "                        initial_box_mapping=initial_box_mapping,\n",
    "                        initial_room_fixed=initial_room_fixed,\n",
    "                        initial_room_state=initial_room_state)\n",
    "\n",
    "    # Wrap the environment with DummyVecEnv to support testing with PPO\n",
    "    env = DummyVecEnv([lambda: env])\n",
    "\n",
    "    obs = env.reset()\n",
    "\n",
    "    for _ in range(1000):\n",
    "        action, _states = model.predict(obs)\n",
    "        obs, rewards, dones, info = env.step(action)\n",
    "        env.render()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    model = PPO.load(\"sokoban_ppo_model\")\n",
    "    test_sokoban(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe83c0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "704315c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d8fc151",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "148b3f58",
   "metadata": {},
   "source": [
    "# MCTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8596b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gym\n",
    "import gym_sokoban\n",
    "import matplotlib.pyplot as plt\n",
    "from custom_sokoban_env import my_sokoban_env\n",
    "import sokoban_tabular\n",
    "import time\n",
    "import sys\n",
    "import random \n",
    "import itertools\n",
    "import cv2\n",
    "from dqn import train_dqn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "418ed866",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial root node terminal state: False\n",
      "Iteration: 1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 87\u001b[0m\n\u001b[0;32m     84\u001b[0m initial_state \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mreset()  \u001b[38;5;66;03m# Or however you define your initial state\u001b[39;00m\n\u001b[0;32m     86\u001b[0m \u001b[38;5;66;03m# Create a MCTS instance with the game and initial state\u001b[39;00m\n\u001b[1;32m---> 87\u001b[0m my_mcts \u001b[38;5;241m=\u001b[39m \u001b[43mmcts\u001b[49m\u001b[43m(\u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     89\u001b[0m \u001b[38;5;66;03m# Get the best action according to MCTS\u001b[39;00m\n\u001b[0;32m     90\u001b[0m best_action \u001b[38;5;241m=\u001b[39m my_mcts\u001b[38;5;241m.\u001b[39mbest_child()\u001b[38;5;241m.\u001b[39mstate\n",
      "Cell \u001b[1;32mIn[31], line 72\u001b[0m, in \u001b[0;36mmcts\u001b[1;34m(env, iterations)\u001b[0m\n\u001b[0;32m     69\u001b[0m                 node \u001b[38;5;241m=\u001b[39m node\u001b[38;5;241m.\u001b[39mbest_child()\n\u001b[0;32m     70\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     71\u001b[0m \u001b[38;5;66;03m#                 print(\"Node is not fully expanded, expanding...\")  # Debug statement\u001b[39;00m\n\u001b[1;32m---> 72\u001b[0m                 \u001b[43mnode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexpand\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     73\u001b[0m                 node\u001b[38;5;241m.\u001b[39mis_fully_expanded \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m     74\u001b[0m         reward \u001b[38;5;241m=\u001b[39m node\u001b[38;5;241m.\u001b[39mrollout()\n",
      "Cell \u001b[1;32mIn[31], line 26\u001b[0m, in \u001b[0;36mNode.expand\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m action \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv\u001b[38;5;241m.\u001b[39mget_valid_actions():  \u001b[38;5;66;03m# get valid actions for the current state\u001b[39;00m\n\u001b[0;32m     25\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m action \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren:\n\u001b[1;32m---> 26\u001b[0m         next_state, reward, done, info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# take the action\u001b[39;00m\n\u001b[0;32m     27\u001b[0m         child_node \u001b[38;5;241m=\u001b[39m Node(next_state, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv)  \u001b[38;5;66;03m# create a new node with the new state and the environment\u001b[39;00m\n\u001b[0;32m     28\u001b[0m         child_node\u001b[38;5;241m.\u001b[39mis_terminal \u001b[38;5;241m=\u001b[39m done\n",
      "File \u001b[1;32m~\\OneDrive - Queen's University\\Documents\\Queens University\\MMAI 865 - Reinforement Learning\\Final Project\\Sokoban\\custom_sokoban_env.py:96\u001b[0m, in \u001b[0;36mstep\u001b[1;34m(self, action, observation_mode)\u001b[0m\n\u001b[0;32m     94\u001b[0m \n\u001b[0;32m     95\u001b[0m         # Convert the observation to RGB frame\n\u001b[1;32m---> 96\u001b[0m         observation = self.render(mode=observation_mode)\n\u001b[0;32m     97\u001b[0m \n\u001b[0;32m     98\u001b[0m         info = {\n",
      "File \u001b[1;32m~\\OneDrive - Queen's University\\Documents\\Queens University\\MMAI 865 - Reinforement Learning\\Final Project\\Sokoban\\custom_sokoban_env.py:241\u001b[0m, in \u001b[0;36mrender\u001b[1;34m(self, mode, close, scale)\u001b[0m\n\u001b[0;32m    239\u001b[0m assert mode in RENDERING_MODES\n\u001b[0;32m    240\u001b[0m \n\u001b[1;32m--> 241\u001b[0m img = self.get_image(mode, scale)\n\u001b[0;32m    242\u001b[0m \n\u001b[0;32m    243\u001b[0m if 'rgb_array' in mode:\n",
      "File \u001b[1;32m~\\OneDrive - Queen's University\\Documents\\Queens University\\MMAI 865 - Reinforement Learning\\Final Project\\Sokoban\\custom_sokoban_env.py:269\u001b[0m, in \u001b[0;36mget_image\u001b[1;34m(self, mode, scale)\u001b[0m\n\u001b[0;32m    267\u001b[0m     img = room_to_tiny_world_rgb(self.room_state, self.room_fixed, scale=scale)\n\u001b[0;32m    268\u001b[0m else:\n\u001b[1;32m--> 269\u001b[0m     img = room_to_rgb(self.room_state, self.room_fixed)\n\u001b[0;32m    270\u001b[0m \n\u001b[0;32m    271\u001b[0m return img\n",
      "File \u001b[1;32m~\\OneDrive - Queen's University\\Documents\\Queens University\\MMAI 865 - Reinforement Learning\\Final Project\\Sokoban\\render_utils.py:48\u001b[0m, in \u001b[0;36mroom_to_rgb\u001b[1;34m(room, room_structure)\u001b[0m\n\u001b[0;32m     44\u001b[0m player \u001b[38;5;241m=\u001b[39m imageio\u001b[38;5;241m.\u001b[39mimread(player_filename)\n\u001b[0;32m     46\u001b[0m player_on_target_filename \u001b[38;5;241m=\u001b[39m pkg_resources\u001b[38;5;241m.\u001b[39mresource_filename(resource_package,\n\u001b[0;32m     47\u001b[0m                                                             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin((\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msurface\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mplayer_on_target.png\u001b[39m\u001b[38;5;124m'\u001b[39m)))\n\u001b[1;32m---> 48\u001b[0m player_on_target \u001b[38;5;241m=\u001b[39m \u001b[43mimageio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mplayer_on_target_filename\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     50\u001b[0m wall_filename \u001b[38;5;241m=\u001b[39m pkg_resources\u001b[38;5;241m.\u001b[39mresource_filename(resource_package, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin((\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msurface\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwall.png\u001b[39m\u001b[38;5;124m'\u001b[39m)))\n\u001b[0;32m     51\u001b[0m wall \u001b[38;5;241m=\u001b[39m imageio\u001b[38;5;241m.\u001b[39mimread(wall_filename)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\imageio\\__init__.py:97\u001b[0m, in \u001b[0;36mimread\u001b[1;34m(uri, format, **kwargs)\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"imread(uri, format=None, **kwargs)\u001b[39;00m\n\u001b[0;32m     69\u001b[0m \n\u001b[0;32m     70\u001b[0m \u001b[38;5;124;03mReads an image from the specified file. Returns a numpy array, which\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     86\u001b[0m \u001b[38;5;124;03m    to see what arguments are available for a particular format.\u001b[39;00m\n\u001b[0;32m     87\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     89\u001b[0m warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m     90\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStarting with ImageIO v3 the behavior of this function will switch to that of\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     91\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m iio.v3.imread. To keep the current behavior (and make this warning disappear)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     94\u001b[0m     stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[0;32m     95\u001b[0m )\n\u001b[1;32m---> 97\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m imread_v2(uri, \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mformat\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\imageio\\v2.py:227\u001b[0m, in \u001b[0;36mimread\u001b[1;34m(uri, format, **kwargs)\u001b[0m\n\u001b[0;32m    224\u001b[0m imopen_args[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlegacy_mode\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    226\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m imopen(uri, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mri\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mimopen_args) \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[1;32m--> 227\u001b[0m     result \u001b[38;5;241m=\u001b[39m file\u001b[38;5;241m.\u001b[39mread(index\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    229\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\imageio\\core\\legacy_plugin_wrapper.py:147\u001b[0m, in \u001b[0;36mLegacyPlugin.read\u001b[1;34m(self, index, **kwargs)\u001b[0m\n\u001b[0;32m    144\u001b[0m     img \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mstack([im \u001b[38;5;28;01mfor\u001b[39;00m im \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miter(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)])\n\u001b[0;32m    145\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m img\n\u001b[1;32m--> 147\u001b[0m reader \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlegacy_get_reader(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    148\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m reader\u001b[38;5;241m.\u001b[39mget_data(index)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\imageio\\core\\legacy_plugin_wrapper.py:116\u001b[0m, in \u001b[0;36mLegacyPlugin.legacy_get_reader\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    113\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format\u001b[38;5;241m.\u001b[39mget_reader(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_request)\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_request\u001b[38;5;241m.\u001b[39mget_file()\u001b[38;5;241m.\u001b[39mseek(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m--> 116\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_format\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_reader\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\imageio\\core\\format.py:221\u001b[0m, in \u001b[0;36mFormat.get_reader\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    217\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m select_mode \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodes:\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    219\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFormat \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m cannot read in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrequest\u001b[38;5;241m.\u001b[39mmode\u001b[38;5;241m.\u001b[39mimage_mode\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m mode\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    220\u001b[0m     )\n\u001b[1;32m--> 221\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mReader\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\imageio\\core\\format.py:312\u001b[0m, in \u001b[0;36mFormat._BaseReaderWriter.__init__\u001b[1;34m(self, format, request)\u001b[0m\n\u001b[0;32m    310\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_request \u001b[38;5;241m=\u001b[39m request\n\u001b[0;32m    311\u001b[0m \u001b[38;5;66;03m# Open the reader/writer\u001b[39;00m\n\u001b[1;32m--> 312\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_open(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest\u001b[38;5;241m.\u001b[39mkwargs\u001b[38;5;241m.\u001b[39mcopy())\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\imageio\\plugins\\pillow_legacy.py:391\u001b[0m, in \u001b[0;36mPNGFormat.Reader._open\u001b[1;34m(self, pilmode, as_gray, ignoregamma)\u001b[0m\n\u001b[0;32m    390\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_open\u001b[39m(\u001b[38;5;28mself\u001b[39m, pilmode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, as_gray\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, ignoregamma\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m--> 391\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mPillowFormat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mReader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_open\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpilmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpilmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mas_gray\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mas_gray\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\imageio\\plugins\\pillow_legacy.py:297\u001b[0m, in \u001b[0;36mPillowFormat.Reader._open\u001b[1;34m(self, pilmode, as_gray)\u001b[0m\n\u001b[0;32m    295\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_im\u001b[38;5;241m.\u001b[39mpalette \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_im\u001b[38;5;241m.\u001b[39mpalette\u001b[38;5;241m.\u001b[39mdirty:\n\u001b[0;32m    296\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_im\u001b[38;5;241m.\u001b[39mpalette\u001b[38;5;241m.\u001b[39mrawmode_saved \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_im\u001b[38;5;241m.\u001b[39mpalette\u001b[38;5;241m.\u001b[39mrawmode\n\u001b[1;32m--> 297\u001b[0m \u001b[43mpil_try_read\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_im\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    298\u001b[0m \u001b[38;5;66;03m# Store args\u001b[39;00m\n\u001b[0;32m    299\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(\n\u001b[0;32m    300\u001b[0m     as_gray\u001b[38;5;241m=\u001b[39mas_gray, is_gray\u001b[38;5;241m=\u001b[39m_palette_is_grayscale(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_im)\n\u001b[0;32m    301\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\imageio\\plugins\\pillow_legacy.py:648\u001b[0m, in \u001b[0;36mpil_try_read\u001b[1;34m(im)\u001b[0m\n\u001b[0;32m    645\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpil_try_read\u001b[39m(im):\n\u001b[0;32m    646\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    647\u001b[0m         \u001b[38;5;66;03m# this will raise an IOError if the file is not readable\u001b[39;00m\n\u001b[1;32m--> 648\u001b[0m         \u001b[43mim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetdata\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    649\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    650\u001b[0m         site \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttp://pillow.readthedocs.io/en/latest/installation.html\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\PIL\\Image.py:1381\u001b[0m, in \u001b[0;36mImage.getdata\u001b[1;34m(self, band)\u001b[0m\n\u001b[0;32m   1363\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgetdata\u001b[39m(\u001b[38;5;28mself\u001b[39m, band\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m   1364\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1365\u001b[0m \u001b[38;5;124;03m    Returns the contents of this image as a sequence object\u001b[39;00m\n\u001b[0;32m   1366\u001b[0m \u001b[38;5;124;03m    containing pixel values.  The sequence object is flattened, so\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1378\u001b[0m \u001b[38;5;124;03m    :returns: A sequence-like object.\u001b[39;00m\n\u001b[0;32m   1379\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1381\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1382\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m band \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1383\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mim\u001b[38;5;241m.\u001b[39mgetband(band)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\PIL\\ImageFile.py:269\u001b[0m, in \u001b[0;36mImageFile.load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    266\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(msg)\n\u001b[0;32m    268\u001b[0m b \u001b[38;5;241m=\u001b[39m b \u001b[38;5;241m+\u001b[39m s\n\u001b[1;32m--> 269\u001b[0m n, err_code \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    270\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    271\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "class Node:\n",
    "    def __init__(self, state, env):\n",
    "        self.state = state\n",
    "        self.is_terminal = env._check_if_done()  # use your own termination check function\n",
    "        self.is_fully_expanded = self.is_terminal\n",
    "        self.children = {}\n",
    "        self.parent = None  # parent node\n",
    "        self.num_visits = 0\n",
    "        self.total_reward = 0  # sum of rewards\n",
    "        self.env = env  # store the environment\n",
    "\n",
    "#     def expand(self):\n",
    "#         for action in self.env.get_valid_actions():  # get valid actions for the current state\n",
    "#             if action not in self.children:\n",
    "#                 next_state, reward, done, info = self.env.step(action)  # take the action\n",
    "#                 child_node = Node(next_state, self.env)  # create a new node with the new state and the environment\n",
    "#                 child_node.is_terminal = done\n",
    "#                 child_node.parent = self  # set the parent of the new node\n",
    "#                 self.children[action] = (child_node, reward)\n",
    "                \n",
    "    def expand(self):\n",
    "        for action in self.env.get_valid_actions():  # get valid actions for the current state\n",
    "            if action not in self.children:\n",
    "                next_state, reward, done, info = self.env.step(action)  # take the action\n",
    "                child_node = Node(next_state, self.env)  # create a new node with the new state and the environment\n",
    "                child_node.is_terminal = done\n",
    "                child_node.parent = self  # set the parent of the new node\n",
    "                self.children[action] = (child_node, reward)\n",
    "                \n",
    "    def best_child(self, c_param=1.0):\n",
    "        choices_weights = []\n",
    "        for child_node, _ in self.children.values():\n",
    "            if child_node.num_visits == 0:\n",
    "                choices_weights.append(float(\"inf\"))  # prioritize exploration for unvisited nodes\n",
    "            else:\n",
    "                choices_weights.append((child_node.total_reward / child_node.num_visits) + \n",
    "                                       c_param * np.sqrt((2 * np.log(self.num_visits) / child_node.num_visits)))\n",
    "        best_action = list(self.children.keys())[np.argmax(choices_weights)]\n",
    "        return self.children[best_action][0]  # Return the child node, not the action\n",
    "\n",
    "\n",
    "\n",
    "    def rollout(self):\n",
    "        current_rollout_state = self.state\n",
    "        while not self.env.is_done(current_rollout_state):  # use your own termination check function\n",
    "            possible_moves = self.env.get_valid_actions(current_rollout_state)\n",
    "            action = self.rollout_policy(possible_moves)\n",
    "            next_state, reward, done, info = self.env.step(action)\n",
    "            current_rollout_state = next_state\n",
    "        return self.env.get_reward(current_rollout_state)  # return reward of terminal state\n",
    "\n",
    "    @staticmethod\n",
    "    def rollout_policy(possible_moves):\n",
    "        return possible_moves[np.random.randint(len(possible_moves))]\n",
    "\n",
    "def mcts(env, iterations):\n",
    "    root = Node(env.reset(), env)\n",
    "    root.is_terminal = env._check_if_done()\n",
    "    print(\"Initial root node terminal state:\", root.is_terminal)  # Debug statement\n",
    "    for i in range(iterations):\n",
    "        print(\"Iteration:\", i+1)  # Debug statement\n",
    "        node = root\n",
    "        while not node.is_terminal:\n",
    "#             print(\"Node terminal state:\", node.is_terminal)  # Debug statement\n",
    "            if node.is_fully_expanded:\n",
    "#                 print(\"Node is fully expanded, getting best child...\")  # Debug statement\n",
    "                node = node.best_child()\n",
    "            else:\n",
    "#                 print(\"Node is not fully expanded, expanding...\")  # Debug statement\n",
    "                node.expand()\n",
    "                node.is_fully_expanded = True\n",
    "        reward = node.rollout()\n",
    "        print(\"Rollout reward:\", reward)  # Debug statement\n",
    "        while node is not None:\n",
    "            node.num_visits += 1\n",
    "            node.total_reward += reward\n",
    "            node = node.parent\n",
    "    return root\n",
    "\n",
    "# You can then use the tree like this:\n",
    "\n",
    "initial_state = env.reset()  # Or however you define your initial state\n",
    "\n",
    "# Create a MCTS instance with the game and initial state\n",
    "my_mcts = mcts(env, 1000)\n",
    "\n",
    "# Get the best action according to MCTS\n",
    "best_action = my_mcts.best_child().state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e6908f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
